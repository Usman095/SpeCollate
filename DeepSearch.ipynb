{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "import numpy as np\n",
    "import random as rand\n",
    "import queue\n",
    "import csv\n",
    "from collections import OrderedDict\n",
    "from IPython.display import clear_output\n",
    "import csv\n",
    "import re\n",
    "from heapq import merge\n",
    "from sklearn import preprocessing\n",
    "from operator import itemgetter\n",
    "import bisect\n",
    "import pickle\n",
    "\n",
    "from sklearn.datasets import make_circles, make_moons\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from IPython.core.debugger import set_trace\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "from IPython.display import display\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        #self.conv1 = nn.Conv2d(1, 64, 7)\n",
    "        self.linear1_1 = nn.Linear(specsize, 1024)\n",
    "        self.linear1_2 = nn.Linear(1024, 512)\n",
    "        self.linear1_3 = nn.Linear(1024, 512)\n",
    "        #self.linear1_3 = nn.Linear(256, 128)\n",
    "        self.linear1_4 = nn.Linear(512, 256)\n",
    "        \n",
    "        self.lstm2_1 = nn.Linear(specsize, 1024)\n",
    "        self.linear2_1 = nn.Linear(1024, 512)\n",
    "        self.linear2_2 = nn.Linear(512, 256)\n",
    "        #self.pool1 = nn.MaxPool2d(2)\n",
    "        #self.conv2 = nn.Conv2d(64, 128, 5)\n",
    "        #self.conv3 = nn.Conv2d(128, 256, 5)\n",
    "        \n",
    "        self.linear1 = nn.Linear(128, 2)\n",
    "        self.linear2 = nn.Linear(64, 2)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "        #self.linear2 = nn.Linear(512, 2)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        res = []\n",
    "        for i in range(data.shape[1]):\n",
    "            x = data[:, i]\n",
    "            x = self.linear1_1(x.view(-1, specsize))\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, training=self.training)\n",
    "            x = self.linear1_2(x)\n",
    "            x = F.relu(x)\n",
    "            #x = self.linear1_3(x)\n",
    "            #x = F.relu(x)\n",
    "            res.append(x)\n",
    "        \n",
    "#         x1 = data[:,0]\n",
    "#         x1 = self.linear1_1(x1.view(-1, specsize))\n",
    "#         x1 = F.relu(x1)\n",
    "#         x1 = F.dropout(x1, training=self.training)\n",
    "        \n",
    "#         x1 = self.linear1_2(x1)\n",
    "#         x1 = F.relu(x1)\n",
    "        \n",
    "#         x1 = self.linear1_3(x1)\n",
    "#         x1 = F.relu(x1)\n",
    "        \n",
    "# #         x1 = self.linear1_3(x1)\n",
    "# #         x1 = F.relu(x1)\n",
    "        \n",
    "# #         x1 = self.linear1_4(x1)\n",
    "# #         x1 = F.relu(x1)\n",
    "        \n",
    "#         x2 = data[:,1]\n",
    "        \n",
    "#         x2 = self.linear1_1(x2.view(-1, specsize))\n",
    "#         x2 = F.relu(x2)\n",
    "#         x2 = F.dropout(x2, training=self.training)\n",
    "        \n",
    "#         x2 = self.linear1_2(x2)\n",
    "#         x2 = F.relu(x2)\n",
    "        \n",
    "#         x2 = self.linear1_3(x2)\n",
    "#         x2 = F.relu(x2)\n",
    "        \n",
    "#         x2 = self.linear1_3(x2)\n",
    "#         x2 = F.relu(x2)\n",
    "        \n",
    "#         x2 = self.linear1_4(x2)\n",
    "#         x2 = F.relu(x2)\n",
    "        #res = F.pairwise_distance(x1, x2)\n",
    "        #res = torch.abs(x1 - x2)\n",
    "        #print(res.shape)\n",
    "        #res = self.linear1(res)\n",
    "        #res = self.linear2(res)\n",
    "        \n",
    "        #return F.log_softmax(res, 1)\n",
    "        return res\n",
    "        \n",
    "#        for i in range(2): # Siamese nets; sharing weights\n",
    "#            x = data[i]\n",
    "#            x = self.conv1(x)\n",
    "#            x = F.relu(x)\n",
    "#            x = self.pool1(x)\n",
    "#            x = self.conv2(x)\n",
    "#            x = F.relu(x)\n",
    "#            x = self.conv3(x)\n",
    "#            x = F.relu(x)\n",
    "#            \n",
    "#            x = x.view(x.shape[0], -1)\n",
    "#            x = self.linear1(x)\n",
    "#            res.append(F.relu(x))\n",
    "#        \n",
    "#        res = torch.abs(res[1] - res[0])\n",
    "#        res = self.linear2(res)\n",
    "#        return res\n",
    "    def name(self):\n",
    "        return \"Net\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (linear1_1): Linear(in_features=8000, out_features=1024, bias=True)\n",
       "  (linear1_2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (linear1_3): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (linear1_4): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (lstm2_1): Linear(in_features=8000, out_features=1024, bias=True)\n",
       "  (linear2_1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (linear2_2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (linear1): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (linear2): Linear(in_features=64, out_features=2, bias=True)\n",
       "  (dropout): Dropout(p=0.1)\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('models/siamese99.4%working_1.pt')\n",
    "model.eval()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runModel(loader):\n",
    "    with torch.no_grad():\n",
    "        accurate_labels = 0\n",
    "        all_labels = 0\n",
    "        loss = 0\n",
    "        out = []\n",
    "        for batch_idx, data in enumerate(loader):\n",
    "\n",
    "            data = data.to(device)    \n",
    "            out.extend(model(data)[0].cpu().detach().numpy())\n",
    "    print(len(out))\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand.seed(37)\n",
    "AAs = 'ACDEFGHIKLMNPQRSTVWY'\n",
    "AAMass = {'A':71.037114, 'C':103.009185, 'D':115.026943, 'E':129.042593, 'F':147.068414, 'G':57.021464, 'H':137.058912,\n",
    "          'I':113.084064, 'K':128.094963, 'L':113.084064, 'M':131.040485, 'N':114.042927, 'P':97.052764, 'Q':128.058578,\n",
    "          'R':156.101111, 'S':87.032028, 'T':101.047679, 'V':99.068414, 'W':186.079313, 'Y':163.0633}\n",
    "\n",
    "H2O = 18.01528\n",
    "PROTON = 1.00727647\n",
    "specsize = 8000\n",
    "precursor_tolerance = 3.0\n",
    "num_psm = 1\n",
    "charge = 2\n",
    "use_mods = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = 1024\n",
    "\n",
    "def GetAAMass(AA):\n",
    "    return AAMass[AA] + 57.021464 if AA == 'C' else AAMass[AA]\n",
    "\n",
    "def GetSpectrum(Seq):\n",
    "    Seq = re.sub('[^ACDEFGHIKLMNPQRSTVWY]', '', Seq) #remove non-amino acids\n",
    "    size = len(Seq)\n",
    "    outsize = 2*size\n",
    "    bspectrum = []\n",
    "    yspectrum = []\n",
    "    \n",
    "    bspectrum.append(GetAAMass(Seq[0]) + PROTON)\n",
    "    yspectrum.append(GetAAMass(Seq[-1]) + H2O + PROTON)\n",
    "    \n",
    "    for i, (fAA, bAA) in enumerate(zip((Seq[1:]), Seq[-2::-1])):\n",
    "        bspectrum.append(bspectrum[i] + GetAAMass(fAA))\n",
    "        yspectrum.append(yspectrum[i] + GetAAMass(bAA))\n",
    "        \n",
    "    mergedout = list(merge(bspectrum, yspectrum))\n",
    "    if mergedout[-1] > specsize:\n",
    "        print(mergedout[-1])\n",
    "        print(Seq)\n",
    "    tspec = np.zeros(specsize)\n",
    "    tspec[np.rint(mergedout).astype(int)] = 1\n",
    "    return tspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readmgfs(folderPath, charge=None):\n",
    "    \n",
    "    mgffiles = [f for f in listdir(folderPath) if isfile(join(folderPath, f)) and f.split('.')[-1] == 'mgf']\n",
    "    assert len(mgffiles) > 0\n",
    "    \n",
    "    spectra = []\n",
    "    masses = []\n",
    "    charges = []\n",
    "    for file in mgffiles:\n",
    "        f = open(join(folderPath, file))\n",
    "        speclines = f.readlines()\n",
    "        f.close()\n",
    "        \n",
    "        if not speclines:\n",
    "            continue\n",
    "            \n",
    "        spec = np.zeros(specsize)\n",
    "        isMass = isCharge = isSpec = False\n",
    "        i = 0\n",
    "        '''Read Headers'''\n",
    "        while True:\n",
    "            line = speclines[i]\n",
    "            i += 1\n",
    "            \n",
    "            splits = line.split('=')\n",
    "            if splits[0].upper() == 'PEPMASS':\n",
    "                masses.append(float(splits[1].split(' ')[0]))\n",
    "                isMass = True\n",
    "                \n",
    "            if isMass and splits[0].upper() == 'CHARGE':\n",
    "                l_charge = int(splits[1][0])\n",
    "                if charge and l_charge != charge:\n",
    "                    del masses[-1]\n",
    "                    isMass = False\n",
    "                    isCharge = False\n",
    "                else:\n",
    "                    charges.append(l_charge)\n",
    "                    isCharge = True\n",
    "                break\n",
    "        \n",
    "        '''Read Spectrum'''\n",
    "        while isMass and isCharge and i < len(speclines):\n",
    "            line = speclines[i]\n",
    "            i += 1\n",
    "            \n",
    "            if line != '\\n' and 'END IONS' not in line.upper():\n",
    "                splits = line.split(' ')\n",
    "                moz, intensity = float(splits[0]), float(splits[1])\n",
    "                spec[round(moz)] += round(intensity)\n",
    "            elif 'END IONS' in line.upper():\n",
    "                break\n",
    "                \n",
    "        if isMass and isCharge:        \n",
    "            spec = np.clip(spec, None, 1000.0)\n",
    "            spec = preprocessing.scale(spec)\n",
    "            spectra.append(spec)\n",
    "        \n",
    "    return spectra, masses, charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readms2(file, charge=None):\n",
    "    f = open(file)\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "    \n",
    "    spectra = []\n",
    "    masses = []\n",
    "    charges = []\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        line = lines[i][:-1]\n",
    "        i += 1\n",
    "        \n",
    "        splits = line.split('\\t')\n",
    "        if splits[0] == 'Z' and (charge is None or float(splits[1]) == charge):\n",
    "            charges.append(float(splits[1]))\n",
    "            masses.append(float(splits[2]))\n",
    "            spec = np.zeros(specsize)\n",
    "            while i < len(lines):\n",
    "                line = lines[i][:-1] #remove the \\n character\n",
    "                i += 1\n",
    "                splits = line.split(' ')\n",
    "                if 'S' in splits[0]:\n",
    "                    break\n",
    "                if 'Z' in splits[0]:\n",
    "                    continue\n",
    "                moz, intensity = float(splits[0]), float(splits[1])\n",
    "                spec[round(moz)] += round(intensity)\n",
    "            \n",
    "            spec = np.clip(spec, None, 1000.0)\n",
    "            spec = preprocessing.scale(spec)\n",
    "            spectra.append(spec)\n",
    "            \n",
    "    return spectra, masses, charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "150\n"
     ]
    }
   ],
   "source": [
    "ms2file = '/disk/raptor/lclhome/mtari008/Proteomics/crux/specs/demo.ms2'\n",
    "\n",
    "#queryspectra, spectramasses, _ = readmgfs(specsPath, charge=2)\n",
    "queryspectra, spectramasses, _ = readms2(ms2file, None)\n",
    "with torch.no_grad():\n",
    "    queryspectraTensor = torch.tensor(queryspectra, dtype=torch.float)[:, None, :]\n",
    "    queryspectra_loader = torch.utils.data.DataLoader(dataset=queryspectraTensor, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    queryspectra_out = runModel(queryspectra_loader)\n",
    "print(len(queryspectra_out))\n",
    "del queryspectraTensor\n",
    "del queryspectra_loader\n",
    "del queryspectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fastatospectra(lines, start, count, dh):\n",
    "    tspectra = []\n",
    "    masses = []\n",
    "    peps = []\n",
    "    \n",
    "    new = prev = 0\n",
    "    end = min(start+count, len(lines))\n",
    "    for i, line in enumerate(lines[start:end]):\n",
    "        splits = line.split('\\t')\n",
    "        \n",
    "        pep = splits[0]\n",
    "        #print(pep)\n",
    "        peps.append(pep)\n",
    "        spec = GetSpectrum(pep)\n",
    "        tspectra.append(preprocessing.scale(spec))\n",
    "        masses.append(float(splits[1]))\n",
    "        \n",
    "        #print(splits[1])\n",
    "        '''Progress Monitor'''\n",
    "        new = int(((i+start)/len(lines)) * 100)\n",
    "        if (new > prev):\n",
    "            dh.update(str(new)+'%')\n",
    "            prev = new\n",
    "            \n",
    "    return tspectra, masses, peps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fastaToSpectraBatch(filePath, spectra_batch_size):    \n",
    "    f = open(filePath)\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "    masses = []\n",
    "    spectra_out = []\n",
    "    peps = []\n",
    "    \n",
    "    dh = display('0%', display_id=True)\n",
    "    \n",
    "    start = 0\n",
    "    i = 0\n",
    "    while start < len(lines):\n",
    "        print('Batch: ' + str(i))\n",
    "        i += 1\n",
    "        \n",
    "        print('Generating spectra...')\n",
    "        spectra, l_masses, l_peps = fastatospectra(lines, start, spectra_batch_size, dh)\n",
    "        masses.extend(l_masses)\n",
    "        peps.extend(l_peps)\n",
    "        start = start + spectra_batch_size\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            print('Converting to tensor...')\n",
    "            '''dtype=torch.float'''\n",
    "            spectra = np.asarray(spectra)\n",
    "            spectraTensor = torch.as_tensor(spectra, dtype=torch.float)[:, None, :]\n",
    "            spectra_loader = torch.utils.data.DataLoader(dataset=spectraTensor, batch_size=batch_size, shuffle=False)\n",
    "            \n",
    "            print('Running the model...')\n",
    "            spectra_out.extend(runModel(spectra_loader))\n",
    "            \n",
    "    return spectra_out, masses, peps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'99%'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0\n",
      "Generating spectra...\n",
      "Converting to tensor...\n",
      "Running the model...\n",
      "6005\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'99%'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0\n",
      "Generating spectra...\n",
      "Converting to tensor...\n",
      "Running the model...\n",
      "6005\n",
      "6005 6005\n",
      "6005 6005\n"
     ]
    }
   ],
   "source": [
    "spectra_batch_size = 500000\n",
    "#targetPath = '/disk/raptor/lclhome/mtari008/Proteogenomics/DeepSNAP/data/rat/peptide-dbs/rat-peptides.target.txt'\n",
    "#decoyPath = '/disk/raptor/lclhome/mtari008/Proteogenomics/DeepSNAP/data/rat/peptide-dbs/rat-peptides.decoy.txt'\n",
    "targetPath = '/disk/raptor/lclhome/mtari008/Proteomics/crux/crux-output/generate-peptides.target.txt'\n",
    "decoyPath = '/disk/raptor/lclhome/mtari008/Proteomics/crux/crux-output/generate-peptides.decoy.txt'\n",
    "targetspectra_out, targetmasses, targetpeptides = fastaToSpectraBatch(targetPath, spectra_batch_size)\n",
    "decoyspectra_out, decoymasses, decoypeptides = fastaToSpectraBatch(decoyPath, spectra_batch_size)\n",
    "\n",
    "\n",
    "print(len(targetspectra_out), len(targetmasses))\n",
    "print(len(decoyspectra_out), len(decoymasses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(616.3776, 630.3821, 646.3519, 647.3107, 658.3518, 658.4246, 661.3879, 673.3879, 673.3992, 686.4195)\n",
      "6005\n"
     ]
    }
   ],
   "source": [
    "print(targetmasses[0:10])\n",
    "print(len(decoypeptides))\n",
    "targetspectra_out, targetmasses, targetpeptides = list(zip(*sorted(zip(targetspectra_out, targetmasses, targetpeptides), \n",
    "                                                                   key=lambda pair: pair[1])))\n",
    "decoyspectra_out, decoymasses, decoypeptides = list(zip(*sorted(zip(decoyspectra_out, decoymasses, decoypeptides),\n",
    "                                                                key=lambda pair: pair[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6005\n",
      "(1032.5069, 1032.5319, 1032.5546, 1032.562, 1032.5659, 1032.5871, 1032.6048, 1033.5096, 1033.5426, 1033.546)\n",
      "(1032.5069, 1032.5319, 1032.5546, 1032.562, 1032.5659, 1032.5871, 1032.6048, 1033.5096, 1033.5426, 1033.546)\n"
     ]
    }
   ],
   "source": [
    "print(len(targetmasses))\n",
    "print(targetmasses[1000:1010])\n",
    "print(decoymasses[1000:1010])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_range(arr, val, tolerance=3):\n",
    "    assert len(arr) > 0\n",
    "    assert tolerance > 0\n",
    "    assert val > 0\n",
    "    \n",
    "    left = val - tolerance if val - tolerance >= 0 else 0\n",
    "    right = val + tolerance\n",
    "    \n",
    "    ileft = bisect.bisect_left(arr, left)\n",
    "    iright = bisect.bisect_right(arr, right)\n",
    "    \n",
    "    return (ileft, iright-1) if iright - ileft > 0 else (-1, -1)\n",
    "    \n",
    "# Function to insert element \n",
    "def insert(lst, n): \n",
    "    assert not lst or len(lst[0]) == len(n)\n",
    "    \n",
    "    index = num_psm\n",
    "    # Searching for the position \n",
    "    for i in range(len(lst)): \n",
    "        if lst[i][0] > n[0]: \n",
    "            index = i \n",
    "            break\n",
    "      \n",
    "    # Inserting n in the list \n",
    "    lst = lst[:index] + [n] + lst[index:] \n",
    "    return lst[:num_psm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_L2_Dist(queryspectra, querymasses, dbspectra, dbmasses, pre_tol=3, keep_psm=1):\n",
    "    prev = 0\n",
    "    psm_scores = []\n",
    "    psm_pepids = []\n",
    "    \n",
    "    for ind, (spec, spec_mass) in enumerate(zip(queryspectra, querymasses)):\n",
    "        left, right = find_range(dbmasses, spec_mass, pre_tol)\n",
    "        if left != -1 and right != -1:\n",
    "            candidate_specs = dbspectra[left:right+1]\n",
    "            l_scores = np.linalg.norm(np.subtract(candidate_specs, spec), axis=1)**2\n",
    "            psm_pepids.append(left + l_scores.argsort()[:keep_psm]) #add argsort later\n",
    "            psm_scores.append(np.sort(l_scores)[:keep_psm])\n",
    "            #print(ind)\n",
    "            new = int((ind/len(queryspectra)) * 100)\n",
    "            if new > prev:\n",
    "                clear_output(wait=True)\n",
    "                print(str(new) + '%')\n",
    "                prev = new\n",
    "        else:\n",
    "            print('***********error**************')\n",
    "            print('ind: ' + str(ind))\n",
    "            print('spec_mass: ' + str(spec_mass))\n",
    "            print('**********end error************')\n",
    "            \n",
    "    return psm_scores, psm_pepids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_xcorr(queryspectra, querymasses, dbspectra, dbmasses, pre_tol=3, keep_psm=1):\n",
    "    prev = 0\n",
    "    psm_scores = []\n",
    "    psm_pepids = []\n",
    "    \n",
    "    for ind, (spec, spec_mass) in enumerate(zip(queryspectra, querymasses)):\n",
    "        left, right = find_range(dbmasses, spec_mass, pre_tol)\n",
    "        if left != -1 and right != -1:\n",
    "            candidate_specs = dbspectra[left:right+1]\n",
    "            l_scores = np.dot(candidate_specs, spec)\n",
    "            psm_pepids.append(left + l_scores.argsort()[::-1][:keep_psm]) #add argsort later\n",
    "            psm_scores.append(np.sort(l_scores)[::-1][:keep_psm])\n",
    "            #print(ind)\n",
    "            new = int((ind/len(queryspectra)) * 100)\n",
    "            if new > prev:\n",
    "                clear_output(wait=True)\n",
    "                print(str(new) + '%')\n",
    "                prev = new\n",
    "        else:\n",
    "            print('***********error**************')\n",
    "            print('ind: ' + str(ind))\n",
    "            print('spec_mass: ' + str(spec_mass))\n",
    "            print('**********end error************')\n",
    "            \n",
    "    return psm_scores, psm_pepids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99%\n"
     ]
    }
   ],
   "source": [
    "# targetpsm_scores, targetpsm_ids = calculate_L2_Dist(queryspectra_out, spectramasses, targetspectra_out,\n",
    "#                                      targetmasses, precursor_tolerance, num_psm)\n",
    "# decoypsm_scores, decoypsm_ids = calculate_L2_Dist(queryspectra_out, spectramasses, decoyspectra_out,\n",
    "#                                      decoymasses, precursor_tolerance, num_psm)\n",
    "targetpsm_scores, targetpsm_ids = calculate_xcorr(queryspectra_out, spectramasses, targetspectra_out,\n",
    "                                     targetmasses, precursor_tolerance, num_psm)\n",
    "decoypsm_scores, decoypsm_ids = calculate_xcorr(queryspectra_out, spectramasses, decoyspectra_out,\n",
    "                                     decoymasses, precursor_tolerance, num_psm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n"
     ]
    }
   ],
   "source": [
    "print(targetmasses[2000000:2000010])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6005\n",
      "6005\n",
      "150\n",
      "150\n",
      "[array([119.93341], dtype=float32), array([119.42667], dtype=float32), array([92.465195], dtype=float32), array([70.95618], dtype=float32), array([81.353226], dtype=float32), array([98.86684], dtype=float32), array([86.25241], dtype=float32), array([101.92701], dtype=float32), array([88.03976], dtype=float32), array([87.60692], dtype=float32)]\n",
      "[array([120.65355], dtype=float32), array([131.83395], dtype=float32), array([83.25646], dtype=float32), array([75.8531], dtype=float32), array([75.34193], dtype=float32), array([103.34235], dtype=float32), array([101.130066], dtype=float32), array([95.64265], dtype=float32), array([91.43796], dtype=float32), array([81.032326], dtype=float32)]\n",
      "[1825 2519 2290   32 1299 2443   28  842 5679 1621]\n",
      "[1829 2519 2297   29 1304 2443   27  839 5680 1623]\n",
      "[195.31476  155.87149  154.71373  153.74385  144.41605  140.9835\n",
      " 139.00238  138.27695  137.98456  136.98334  136.33673  134.513\n",
      " 132.89551  129.94763  126.72832  125.20219  123.55231  121.66821\n",
      " 119.93341  119.82553  119.42667  119.00085  117.95119  117.92219\n",
      " 117.721634 117.420334 115.41861  114.51394  114.44134  113.95644\n",
      " 113.875946 113.49554  112.99895  111.89251  111.81023  110.87637\n",
      " 110.09053  109.7374   109.72711  108.46753  106.55447  106.4382\n",
      " 106.13118  106.07416  105.61763  105.39874  105.0351   103.37543\n",
      " 101.92701  101.45397   98.86684   97.685486  97.592606  97.30902\n",
      "  96.13195   95.9413    95.89013   94.75311   94.426346  93.407906\n",
      "  92.62938   92.465195  91.88011   91.27016   90.93083   90.68437\n",
      "  90.36142   89.324936  89.02522   88.97537   88.83364   88.79057\n",
      "  88.14104   88.03976   87.70526   87.69175   87.60692   86.25241\n",
      "  86.22511   85.64073   85.63452   85.45451   85.37846   85.16355\n",
      "  85.098755  84.88267   84.75174   83.967026  83.3947    83.22946\n",
      "  83.19843   83.0087    82.80319   82.6724    82.021805  81.85458\n",
      "  81.68935   81.642944  81.353226  81.177475]\n",
      "[196.85922  167.38649  161.92743  159.93948  153.5637   151.7757\n",
      " 149.50635  148.58781  148.4396   145.23755  142.0538   142.03214\n",
      " 140.96043  140.40033  138.06976  131.97714  131.83395  131.77208\n",
      " 122.14159  121.75687  121.585304 121.580124 120.65355  119.41249\n",
      " 119.38513  118.7191   117.84972  117.793655 116.854416 115.35878\n",
      " 114.58578  113.57991  113.167175 110.6357   110.50639  110.47374\n",
      " 109.91995  109.70685  109.375046 109.118965 109.034775 108.301\n",
      " 108.2049   107.22769  105.19493  104.61774  104.484276 104.366974\n",
      " 103.91736  103.818436 103.34235  102.235596 101.130066 100.86392\n",
      " 100.53214  100.0318    98.686264  97.17079   97.158585  96.67656\n",
      "  96.6683    95.64265   95.36848   93.95889   92.330795  92.12579\n",
      "  91.71637   91.43796   91.22647   90.87262   90.498825  90.388565\n",
      "  89.85283   89.77115   88.98036   88.601074  88.5121    88.485825\n",
      "  88.21996   88.19654   88.0063    87.88068   87.16174   86.90287\n",
      "  86.313065  86.13158   85.97461   85.864136  85.06235   84.92283\n",
      "  84.66052   84.598114  84.395096  83.9289    83.92409   83.86781\n",
      "  83.6303    83.55322   83.46431   83.364426]\n"
     ]
    }
   ],
   "source": [
    "print(len(targetspectra_out))\n",
    "print(len(decoyspectra_out))\n",
    "\n",
    "print(len(targetpsm_scores))\n",
    "print(len(decoypsm_scores))\n",
    "\n",
    "print(targetpsm_scores[0:10])\n",
    "print(decoypsm_scores[0:10])\n",
    "\n",
    "targetpsm_scores = np.asarray(targetpsm_scores).flatten()\n",
    "decoypsm_scores = np.asarray(decoypsm_scores).flatten()\n",
    "\n",
    "targetpsm_ids = np.asarray(targetpsm_ids).flatten()\n",
    "decoypsm_ids = np.asarray(decoypsm_ids).flatten()\n",
    "\n",
    "targetpsm_peps = np.asarray(targetpeptides)[targetpsm_ids]\n",
    "decoypsm_peps = np.asarray(decoypeptides)[decoypsm_ids]\n",
    "\n",
    "#targetpsm_ids = targetpsm_ids[np.argsort(np.asarray(targetpsm_scores).flatten())]\n",
    "#decoypsm_ids = decoypsm_ids[np.argsort(np.asarray(decoypsm_scores).flatten())]\n",
    "\n",
    "sorted_targets = np.sort(np.asarray(targetpsm_scores).flatten())[::-1]\n",
    "sorted_decoys = np.sort(np.asarray(decoypsm_scores).flatten())[::-1]\n",
    "\n",
    "print(targetpsm_ids[0:10])\n",
    "print(decoypsm_ids[0:10])\n",
    "\n",
    "print(sorted_targets[0:100])\n",
    "print(sorted_decoys[0:100])\n",
    "\n",
    "#targetpsm_scores = np.column_stack((targetpsm_scores, np.ones(len(targetpsm_scores))))\n",
    "#decoypsm_scores = np.column_stack((decoypsm_scores, np.zeros(len(decoypsm_scores))))\n",
    "#decoypsm_scores = np.asarray(decoypsm_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([119.93341 , 119.42667 ,  92.465195,  70.95618 ,  81.353226,\n",
       "        98.86684 ,  86.25241 , 101.92701 ,  88.03976 ,  87.60692 ,\n",
       "        92.62938 ,  88.97537 ,  97.592606,  85.64073 ,  67.35411 ,\n",
       "       138.27695 , 154.71373 , 139.00238 ,  94.75311 ,  82.6724  ,\n",
       "        87.70526 ,  90.36142 ,  81.642944,  89.02522 , 101.45397 ,\n",
       "        71.009445,  78.95327 ,  85.16355 ,  80.693184,  86.22511 ,\n",
       "       105.39874 , 117.95119 ,  83.0087  ,  83.967026, 113.95644 ,\n",
       "        65.299255,  83.3947  ,  94.426346, 111.89251 , 117.721634,\n",
       "       121.66821 ,  80.59951 ,  80.03313 , 134.513   ,  72.0045  ,\n",
       "        73.785484,  79.995514, 113.875946, 103.37543 ,  82.021805,\n",
       "        67.84793 , 105.61763 , 125.20219 ,  84.75174 ,  67.29022 ,\n",
       "        71.47301 ,  72.40285 , 155.87149 ,  76.36668 , 111.81023 ,\n",
       "       126.72832 ,  90.68437 , 117.92219 ,  77.77935 ,  75.91037 ,\n",
       "       144.41605 ,  80.47797 , 129.94763 ,  95.9413  ,  85.37846 ,\n",
       "        93.407906,  79.620384,  75.57164 ,  76.36846 ,  72.40297 ,\n",
       "       112.99895 ,  81.68935 ,  87.69175 ,  70.89389 ,  73.7549  ,\n",
       "        74.46442 ,  72.70671 , 123.55231 , 119.82553 , 110.87637 ,\n",
       "       106.4382  , 195.31476 ,  89.324936,  91.88011 ,  96.13195 ,\n",
       "        65.76248 ,  84.88267 ,  97.685486,  82.80319 , 109.72711 ,\n",
       "        73.7769  ,  77.96304 ,  90.93083 , 106.55447 ,  70.42055 ,\n",
       "        88.79057 ,  85.63452 ,  72.675095,  78.3347  , 115.41861 ,\n",
       "        75.00101 ,  97.30902 , 113.49554 ,  95.89013 , 140.9835  ,\n",
       "        81.85458 , 109.7374  ,  73.89542 , 105.0351  ,  68.326355,\n",
       "        79.671   , 132.89551 ,  85.45451 ,  69.9263  ,  79.78119 ,\n",
       "       136.98334 , 136.33673 ,  88.14104 ,  77.3755  ,  91.27016 ,\n",
       "       106.13118 ,  76.52783 , 110.09053 ,  78.76803 ,  83.22946 ,\n",
       "        76.15597 , 108.46753 ,  73.2216  ,  79.72451 , 114.51394 ,\n",
       "        78.19069 , 153.74385 , 114.44134 ,  76.58069 , 117.420334,\n",
       "        88.83364 , 119.00085 , 106.07416 ,  81.177475,  73.9135  ,\n",
       "        73.52792 ,  79.544464,  85.098755,  83.19843 , 137.98456 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetpsm_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    data={'spectrum_ids':np.arange(len(targetpsm_peps)), 'target_psms':targetpsm_peps, \n",
    "          'targetpsm_scores':targetpsm_scores, 'decoy_psms':decoypsm_peps, 'decoypsm_scores':decoypsm_scores})\n",
    "df.to_csv('deepsearch.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedpeps = np.array(sortedpeps)\n",
    "correct_matches = 0\n",
    "for ind, psms in enumerate(psm_scores):\n",
    "    #print('ind: ' + str(ind) + ', mass: ' + str(sortedspecmasses[ind]))\n",
    "    #print('psms: ' + str(psms) + ', psm mass: ' + str(sortedpepmasses[psms[0]]))\n",
    "    cand_peps = sortedpeps[psms]\n",
    "    #print(cand_peps)\n",
    "    for pep in cand_peps:\n",
    "        #print('pepidmass: ' + str(pepidmass[pep][0]))\n",
    "        #print('ids: ' + str(ids[ind]) + ', in: ' + str(pepidmass[pep][0]))\n",
    "        if ids[ind] in pepidmass[pep][0]:\n",
    "            correct_matches += 1\n",
    "            break\n",
    "print(len(psm_scores))\n",
    "print(correct_matches)\n",
    "print(str((correct_matches/len(psm_scores)) * 100) + '% correct matches in top ' + str(num_psm) + ' psms.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(5184 - 1739)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('/disk/raptor/lclhome/mtari008/Proteogenomics/DeepSNAP/data/rat/peptide-dbs/rat-peptides.target.txt')\n",
    "tlines = file.readlines()\n",
    "print(len(tlines))\n",
    "tpeps = list((tline.split('\\t')[0], float(tline.split('\\t')[1])) for tline in tlines)\n",
    "tpeps = sorted(tpeps, key=lambda pair: pair[1])\n",
    "print(tpeps[10000:10010])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('/disk/raptor/lclhome/mtari008/Proteogenomics/DeepSNAP/data/rat/peptide-dbs/rat-peptides.decoy.txt')\n",
    "tlines = file.readlines()\n",
    "print(len(tlines))\n",
    "tpeps = list((tline.split('\\t')[0], float(tline.split('\\t')[1])) for tline in tlines)\n",
    "tpeps = sorted(tpeps, key=lambda pair: pair[1])\n",
    "print(tpeps[10000:10010])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "       143, 144, 145, 146, 147, 148, 149])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
