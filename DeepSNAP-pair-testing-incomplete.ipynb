{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "import numpy as np\n",
    "import random as rand\n",
    "import queue\n",
    "import csv\n",
    "from collections import OrderedDict\n",
    "from IPython.display import clear_output\n",
    "import csv\n",
    "from heapq import merge\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from sklearn.datasets import make_circles, make_moons\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from IPython.core.debugger import set_trace\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand.seed(37)\n",
    "AAMass = {'A':71.037114, 'C':103.009185, 'D':115.026943, 'E':129.042593, 'F':147.068414, 'G':57.021464, 'H':137.058912,\n",
    "          'I':113.084064, 'K':128.094963, 'L':113.084064, 'M':131.040485, 'N':114.042927, 'P':97.052764, 'Q':128.058578,\n",
    "          'R':156.101111, 'S':87.032028, 'T':101.047679, 'V':99.068414, 'W':186.079313, 'Y':163.0633}\n",
    "\n",
    "H2O = 18.015\n",
    "NH3 = 17.031\n",
    "PROTON = 1.00727647\n",
    "specsize = 8000\n",
    "charge = 2\n",
    "use_mods = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing by:\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(8000,)\n",
      "113.084064\n"
     ]
    }
   ],
   "source": [
    "def GetAAMass(AA):\n",
    "    return AAMass[AA] + 57.021464 if AA == 'C' else AAMass[AA]\n",
    "\n",
    "def GetSpectrum(Seq):\n",
    "    size = len(Seq)\n",
    "    outsize = 2*size\n",
    "    bspectrum = []\n",
    "    bspectrumaux = []\n",
    "    yspectrum = []\n",
    "    yspectrumaux = []\n",
    "    \n",
    "    bspectrum.append(GetAAMass(Seq[0]) + PROTON)\n",
    "    yspectrum.append(GetAAMass(Seq[-1]) + H2O + PROTON)\n",
    "    \n",
    "    for i, (fAA, bAA) in enumerate(zip((Seq[1:]), Seq[-2::-1])):\n",
    "        bspectrum.append(bspectrum[i] + GetAAMass(fAA))\n",
    "        yspectrum.append(yspectrum[i] + GetAAMass(bAA))\n",
    "    \n",
    "#    bspectrumaux = [(bion + PROTON) / 2 for bion in bspectrum]\n",
    "#    bspectrumaux.extend([bion - H2O for bion in bspectrum])\n",
    "#    bspectrumaux.extend([bion - NH3 for bion in bspectrum])\n",
    "    \n",
    "#    yspectrumaux = [(yion + PROTON) / 2 for yion in yspectrum]\n",
    "#    yspectrumaux.extend([yion - H2O for yion in yspectrum])\n",
    "#    yspectrumaux.extend([yion - NH3 for yion in yspectrum])\n",
    "    \n",
    "#    bspectrum.extend(bspectrumaux)\n",
    "#    yspectrum.extend(yspectrumaux)\n",
    "    \n",
    "#     bspectrum.sort()\n",
    "#     yspectrum.sort()\n",
    "    \n",
    "    mergedout = list(merge(bspectrum, yspectrum))\n",
    "    if mergedout[-1] > specsize:\n",
    "        print(mergedout[-1])\n",
    "        print(Seq)\n",
    "    tspec = np.zeros(specsize)\n",
    "    tspec[np.rint(mergedout).astype(int)] = 1\n",
    "    return tspec\n",
    "\n",
    "by = GetSpectrum('ACDEFG')\n",
    "print('printing by:\\n' + str(by))\n",
    "print(by.shape)\n",
    "print(AAMass['L'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_signals():\n",
    "    isName = isMW = isNumPeaks = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99%\n",
      "<class 'list'>\n",
      "len of file: 50017570\n",
      "148402\n"
     ]
    }
   ],
   "source": [
    "f = open(\"human_consensus_final_true_lib.msp\", \"r\")\n",
    "lines = f.readlines()\n",
    "newcontents = []\n",
    "specid = 0\n",
    "prev = 0\n",
    "num_specs = 0\n",
    "for i, line in enumerate(lines):\n",
    "    if line.startswith('Name') and '_' in line:\n",
    "        l_charge = int(line[line.find('_') - 1])\n",
    "        if l_charge != charge:\n",
    "            continue\n",
    "        if use_mods:\n",
    "            num_specs += 1\n",
    "        elif '(' not in line and ')' not in line:\n",
    "            num_specs += 1\n",
    "        new = int((i/len(lines)) * 100)\n",
    "        if (new > prev):\n",
    "            clear_output(wait=True)\n",
    "            print(str(new) + '%')\n",
    "            prev = new\n",
    "f.close()\n",
    "print(type(lines))\n",
    "print('len of file: ' + str(len(lines)))\n",
    "print(num_specs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Non Mods:\n",
    "Number of charge 1 examples: 18230  \n",
    "Number of charge 2 examples: 130172  \n",
    "Number of charge 3 examples: 70741  \n",
    "  \n",
    "#### Con Mods:\n",
    "Number of charge 2 examples: 184994"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99%\n",
      "decoy is the same. shuffling\n",
      "decoy is the same. shuffling\n",
      "decoy is the same. shuffling\n",
      "max peaks: 251\n",
      "count: 130172\n",
      "max moz: 2616.7\n"
     ]
    }
   ],
   "source": [
    "if not lines:\n",
    "    f=open(\"human_consensus_final_true_lib.msp\", \"r\")\n",
    "#fo = open('output.csv', 'w')\n",
    "#fo.write('Q,P,N\\n')\n",
    "fixedlen = 300\n",
    "dataset = []\n",
    "label = []\n",
    "lines = f.readlines() if not lines else lines\n",
    "f.close()\n",
    "print('len of file: ' + str(len(lines)))\n",
    "count = 0\n",
    "limit = 200000\n",
    "pep = mass = numPeaks = 0\n",
    "#spec = []\n",
    "isName = isMW = isNumPeaks = False\n",
    "new = prev = 0\n",
    "maxpeaks = maxmoz = 0\n",
    "i = 0\n",
    "while i < len(lines) and limit > 0:\n",
    "    line = lines[i]\n",
    "    i += 1\n",
    "    splits = line.split(':') \n",
    "    if (splits[0] == 'Name') and '_' in line:\n",
    "        split1 = splits[1]\n",
    "        l_charge = int(split1[split1.find('_') - 1])\n",
    "        if l_charge != charge: # l_charge == l_charge always true.\n",
    "            continue\n",
    "        if use_mods:\n",
    "            pep = split1.split('/')[0].lstrip(' ')\n",
    "            isName = True\n",
    "        elif '(' not in splits[1] and ')' not in splits[1]:\n",
    "            pep = split1.split('/')[0].lstrip(' ')\n",
    "            isName = True\n",
    "        \n",
    "    if (isName and splits[0] == 'MW'):\n",
    "        mass = float(splits[1])\n",
    "        if round(mass) < specsize:\n",
    "            isMW = True\n",
    "            #limit = limit - 1\n",
    "        else:\n",
    "            isName = isMW = isNumPeaks = False\n",
    "            continue\n",
    "        \n",
    "    if (isName and isMW and splits[0] == 'Num peaks'):\n",
    "        numPeaks = int(splits[1])\n",
    "        if numPeaks > maxpeaks:\n",
    "            maxpeaks = numPeaks\n",
    "            \n",
    "        spec = np.zeros(specsize)\n",
    "        while (lines[i] != '\\n'):\n",
    "            mzline = lines[i]\n",
    "            i +=1\n",
    "            mzsplits = mzline.split('\\t')\n",
    "            moz, intensity = float(mzsplits[0]), float(mzsplits[1])\n",
    "            if moz > maxmoz:\n",
    "                maxmoz = moz\n",
    "            spec[round(moz)] += round(intensity)\n",
    "        \n",
    "        #padlen = fixedlen - len(spec)\n",
    "        #leftpad = rand.randint(0, padlen)\n",
    "        #rightpad = padlen - leftpad\n",
    "        #npspec = np.reshape(spec, (len(spec), 2))\n",
    "        #npspec = np.pad(npspec, ((leftpad, rightpad), (0, 0)), 'constant', constant_values=(0, 0))\n",
    "        spec = np.clip(spec, None, 1000.0)\n",
    "        spec = preprocessing.scale(spec)\n",
    "        #min_max_scaler = sklearn.preprocessing.MinMaxScaler()\n",
    "        #npspec[:,1] = sklearn.preprocessing.minmax_scale(npspec[:,1])\n",
    "        \n",
    "        isNumPeaks = True\n",
    "        \n",
    "    if isName and isMW and isNumPeaks:\n",
    "        isName = isMW = isNumPeaks = False\n",
    "        revPep = pep[0] + pep[1:-1][::-1] + pep[-1]\n",
    "        if pep == revPep:\n",
    "            print('decoy is the same. shuffling')\n",
    "            revPep = ''.join(rand.sample(revPep,len(revPep)))\n",
    "        #fo.write('\"' + str(list(spec)).strip('[]') + '\",' + str(pep) + ',' + str(revPep) + '\\n')\n",
    "        tspec = preprocessing.scale(GetSpectrum(pep))\n",
    "        rtspec = preprocessing.scale(GetSpectrum(revPep))\n",
    "        #padlen = fixedlen - len(tspec)\n",
    "        #leftpad = rand.randint(0, padlen)\n",
    "        #rightpad = padlen - leftpad\n",
    "        #tspec = np.pad(tspec, ((leftpad, rightpad), (0, 0)), 'constant', constant_values=(0, 0))\n",
    "        #padlen = fixedlen - len(rtspec)\n",
    "        #leftpad = rand.randint(0, padlen)\n",
    "        #rightpad = padlen - leftpad\n",
    "        #rtspec = np.pad(rtspec, ((leftpad, rightpad), (0, 0)), 'constant', constant_values=(0, 0))\n",
    "        \n",
    "        #spectensor = transforms.ToTensor()(spec).view(specsize,-1).float()\n",
    "        #tspectensor = transforms.ToTensor()(tspec).view(specsize,-1).float()\n",
    "        #rtspectensor = transforms.ToTensor()(rtspec).view(specsize,-1).float()\n",
    "        \n",
    "        dataset.append([spec, tspec, rtspec])\n",
    "        label.append([1, -1])\n",
    "        #dataset.append([np.reshape(spec, (len(spec), 2)), tspec, rtspec])\n",
    "        count = count + 1\n",
    "        pep = mass = numPeaks = 0\n",
    "        spec = []\n",
    "        new = int((i/len(lines)) * 100)\n",
    "        if (new > prev):\n",
    "            clear_output(wait=True)\n",
    "            print(str(new) + '%')\n",
    "            prev = new\n",
    "\n",
    "print('max peaks: ' + str(maxpeaks))\n",
    "print('count: ' + str(count))\n",
    "print('max moz: ' + str(maxmoz))\n",
    "#fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(dataset))\n",
    "print(len(label))\n",
    "\n",
    "#dataset[:,0] = preprocessing.scale(dataset[:,0])\n",
    "\n",
    "#transformer = transforms.Compose([transforms.ToTensor(),\n",
    "#                                 transforms.Normalize((0.5,),(1.0,))])\n",
    "\n",
    "#dataset = transformer(dataset)\n",
    "print('splitting...')\n",
    "tmpTrainData, tmpTestData = train_test_split(\n",
    "            dataset, test_size = 0.2, random_state = rand.randint(0, 1000), shuffle = True)\n",
    "\n",
    "tmpTestData = np.asarray(tmpTestData)\n",
    "tmpTestOut = np.append(np.ones(len(tmpTestData)), np.zeros(len(tmpTestData)))\n",
    "tmpTestData = np.concatenate((tmpTestData[:,[0,1]], tmpTestData[:,[0,2]]), axis=0)\n",
    "\n",
    "# XTrainTensor = transformer(tmpTrainData, dtype=torch.float)\n",
    "# XTestTensor = transformer(tmpTestData, dtype=torch.float)\n",
    "# yTrainTensor = transformer(tmpTrainLbl, dtype=torch.long)\n",
    "# yTestTensor = transformer(tmpTestLbl, dtype=torch.long)\n",
    "\n",
    "print('almost done.')\n",
    "XTrainTensor = torch.tensor(tmpTrainData, dtype=torch.float)\n",
    "XTestTensor = torch.tensor(tmpTestData, dtype=torch.float)\n",
    "yTestTensor = torch.tensor(tmpTestOut, dtype=torch.float)\n",
    "\n",
    "testDataset = torch.utils.data.TensorDataset(XTestTensor, yTestTensor)\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "do_learn = True\n",
    "save_frequency = 2\n",
    "lr = 0.00001\n",
    "num_epochs = 200\n",
    "weight_decay = 0.0001\n",
    "margin = 0.2\n",
    "#torch.manual_seed(0)\n",
    "#torch.cuda.manual_seed(0)\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cuda')\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=XTrainTensor,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=testDataset,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True)\n",
    "#torch.save(train_loader, 'train_loader.pt')\n",
    "#torch.save(test_loader, 'test_loader.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'TensorDataset' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-6fdb2e245d9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#train_loader = torch.load('train_loader.pt')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#test_loader = torch.load('test_loader.pt')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestDataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'TensorDataset' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "#train_loader = torch.load('train_loader.pt')\n",
    "#test_loader = torch.load('test_loader.pt')\n",
    "print(testDataset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        #self.conv1 = nn.Conv2d(1, 64, 7)\n",
    "        self.linear1_1 = nn.Linear(specsize, 1024)\n",
    "        self.linear1_2 = nn.Linear(1024, 512)\n",
    "        self.linear1_3 = nn.Linear(1024, 512)\n",
    "        #self.linear1_3 = nn.Linear(256, 128)\n",
    "        self.linear1_4 = nn.Linear(512, 256)\n",
    "        \n",
    "        self.lstm2_1 = nn.Linear(specsize, 1024)\n",
    "        self.linear2_1 = nn.Linear(1024, 512)\n",
    "        self.linear2_2 = nn.Linear(512, 256)\n",
    "        #self.pool1 = nn.MaxPool2d(2)\n",
    "        #self.conv2 = nn.Conv2d(64, 128, 5)\n",
    "        #self.conv3 = nn.Conv2d(128, 256, 5)\n",
    "        \n",
    "        self.linear1 = nn.Linear(128, 2)\n",
    "        self.linear2 = nn.Linear(64, 2)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "        #self.linear2 = nn.Linear(512, 2)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        res = []\n",
    "        for i in range(data.shape[1]):\n",
    "            x = data[:, i]\n",
    "            x = self.linear1_1(x.view(-1, specsize))\n",
    "            x = F.relu(x)\n",
    "            x = F.dropout(x, training=self.training)\n",
    "            x = self.linear1_2(x)\n",
    "            x = F.relu(x)\n",
    "            x = F.normalize(x)\n",
    "            #x = self.linear1_3(x)\n",
    "            #x = F.relu(x)\n",
    "            res.append(x)\n",
    "        \n",
    "#         x1 = data[:,0]\n",
    "#         x1 = self.linear1_1(x1.view(-1, specsize))\n",
    "#         x1 = F.relu(x1)\n",
    "#         x1 = F.dropout(x1, training=self.training)\n",
    "        \n",
    "#         x1 = self.linear1_2(x1)\n",
    "#         x1 = F.relu(x1)\n",
    "        \n",
    "#         x1 = self.linear1_3(x1)\n",
    "#         x1 = F.relu(x1)\n",
    "        \n",
    "# #         x1 = self.linear1_3(x1)\n",
    "# #         x1 = F.relu(x1)\n",
    "        \n",
    "# #         x1 = self.linear1_4(x1)\n",
    "# #         x1 = F.relu(x1)\n",
    "        \n",
    "#         x2 = data[:,1]\n",
    "        \n",
    "#         x2 = self.linear1_1(x2.view(-1, specsize))\n",
    "#         x2 = F.relu(x2)\n",
    "#         x2 = F.dropout(x2, training=self.training)\n",
    "        \n",
    "#         x2 = self.linear1_2(x2)\n",
    "#         x2 = F.relu(x2)\n",
    "        \n",
    "#         x2 = self.linear1_3(x2)\n",
    "#         x2 = F.relu(x2)\n",
    "        \n",
    "#         x2 = self.linear1_3(x2)\n",
    "#         x2 = F.relu(x2)\n",
    "        \n",
    "#         x2 = self.linear1_4(x2)\n",
    "#         x2 = F.relu(x2)\n",
    "        #res = F.pairwise_distance(x1, x2)\n",
    "        #res = torch.abs(x1 - x2)\n",
    "        #print(res.shape)\n",
    "        #res = self.linear1(res)\n",
    "        #res = self.linear2(res)\n",
    "        \n",
    "        #return F.log_softmax(res, 1)\n",
    "        return res\n",
    "        \n",
    "#        for i in range(2): # Siamese nets; sharing weights\n",
    "#            x = data[i]\n",
    "#            x = self.conv1(x)\n",
    "#            x = F.relu(x)\n",
    "#            x = self.pool1(x)\n",
    "#            x = self.conv2(x)\n",
    "#            x = F.relu(x)\n",
    "#            x = self.conv3(x)\n",
    "#            x = F.relu(x)\n",
    "#            \n",
    "#            x = x.view(x.shape[0], -1)\n",
    "#            x = self.linear1(x)\n",
    "#            res.append(F.relu(x))\n",
    "#        \n",
    "#        res = torch.abs(res[1] - res[0])\n",
    "#        res = self.linear2(res)\n",
    "#        return res\n",
    "    def name(self):\n",
    "        return \"Net\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 2, 8000])\n"
     ]
    }
   ],
   "source": [
    "for (tid, data) in enumerate(train_loader):\n",
    "    if tid == 0:\n",
    "        print(data[:,0:3:2].shape)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hinge = torch.nn.HingeEmbeddingLoss()\n",
    "triplet_loss = nn.TripletMarginLoss(margin=margin, p=2, reduction='sum')\n",
    "\n",
    "def train(model, device, train_loader, epoch, optimizer):\n",
    "    model.train()\n",
    "    \n",
    "    accurate_labels = 0\n",
    "    all_labels = 0\n",
    "    for (batch_idx, data) in enumerate(train_loader):\n",
    "        #for i in range(len(data)):\n",
    "        #    data[i] = data[i].to(device)\n",
    "        \n",
    "        data = data.to(device)    \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #output_positive = model(data[:,0:2])\n",
    "        #output_negative = model(data[:,0:3:2])\n",
    "        Q, P, N = model(data)\n",
    "#         target = target.type(torch.LongTensor).to(device)\n",
    "        \n",
    "#         target_positive = torch.squeeze(target[:,0])\n",
    "#         target_negative = torch.squeeze(target[:,1])\n",
    "        \n",
    "        #change the labels back to [1, 0] for cross entropy\n",
    "        #loss_positive = F.cross_entropy(output_positive, target_positive)\n",
    "        #loss_negative = F.cross_entropy(output_negative, target_negative)\n",
    "        #loss_positive = hinge(output_positive, target_positive)\n",
    "        #loss_negative = hinge(output_negative, target_negative)\n",
    "        #print('hinge distance: ' + str(output_positive - output_negative + margin))\n",
    "        #dist_hinge = torch.clamp(output_positive - output_negative + margin, min=0.0)\n",
    "        #loss = torch.sum(dist_hinge)\n",
    "        loss = triplet_loss(Q, P, N)\n",
    "        \n",
    "        \n",
    "        #loss = loss_positive + loss_negative\n",
    "        loss.backward()\n",
    "            \n",
    "        optimizer.step()\n",
    "        \n",
    "        accurate_labels = accurate_labels + 2*torch.sum(F.pairwise_distance(Q, P)**2 - \n",
    "                                                        F.pairwise_distance(Q, N)**2 + margin < 0)\n",
    "        #accurate_labels = accurate_labels + 2*torch.sum(output_positive + margin < output_negative)\n",
    "        #accurate_labels_positive = torch.sum(torch.argmax(output_positive, dim=1) == target_positive).cpu()\n",
    "        #accurate_labels_negative = torch.sum(torch.argmax(output_negative, dim=1) == target_negative).cpu()\n",
    "        \n",
    "        #accurate_labels = accurate_labels + accurate_labels_positive + accurate_labels_negative\n",
    "        all_labels = all_labels + 2*len(Q)  \n",
    "    \n",
    "    accuracy = 100. * float(accurate_labels) / all_labels\n",
    "    print('Epoch: ' + str(epoch))\n",
    "    print('Train accuracy: {}/{} ({:.3f}%)'.format(accurate_labels, all_labels, accuracy))\n",
    "    \n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        accurate_labels = 0\n",
    "        all_labels = 0\n",
    "        loss = 0\n",
    "        \n",
    "        for batch_idx, (data, target) in enumerate(test_loader):\n",
    "            #for i in range(len(data)):\n",
    "            #    data[i] = data[i].to(device)\n",
    "            \n",
    "            data = data.to(device)    \n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            #output_positive = model(data[:,0:2])\n",
    "            #output_negative = model(data[:,0:3:2])\n",
    "            Q, P = model(data)\n",
    "#             target = target.type(torch.LongTensor).to(device)\n",
    "\n",
    "#             target_positive = torch.squeeze(target[:,0])\n",
    "#             target_negative = torch.squeeze(target[:,1])\n",
    "            \n",
    "            #loss_positive = F.cross_entropy(output_positive, target_positive)\n",
    "            #loss_negative = F.cross_entropy(output_negative, target_negative)\n",
    "            #loss_positive = hinge(output_positive, target_positive)\n",
    "            #loss_negative = hinge(output_negative, target_negative)\n",
    "            #dist_hinge = torch.clamp(dist_p - dist_n + self.margin, min=0.0)\n",
    "            \n",
    "            #loss = torch.max(loss_positive - loss_negative + 0.2, 0)#loss + loss_positive + loss_negative\n",
    "            #dist_hinge = torch.clamp(output_positive - output_negative + margin, min=0.0)\n",
    "            #loss = torch.sum(dist_hinge)\n",
    "            #loss = triplet_loss(Q, P, N)\n",
    "            \n",
    "            #accurate_labels = accurate_labels + 2*torch.sum(F.pairwise_distance(Q, P)**2 - \n",
    "            #                                            F.pairwise_distance(Q, N)**2 + margin < 0)\n",
    "            accurate_labels_positive = torch.sum(torch.argmax(output_positive, dim=1) == target_positive).cpu()\n",
    "            #accurate_labels_negative = torch.sum(torch.argmax(output_negative, dim=1) == target_negative).cpu()\n",
    "                \n",
    "            #accurate_labels = accurate_labels + accurate_labels_positive + accurate_labels_negative\n",
    "            #accurate_labels = accurate_labels + 2*torch.sum(output_positive + margin < output_negative)\n",
    "            \n",
    "            all_labels = all_labels + 2*len(Q)\n",
    "                \n",
    "        accuracy = 100. * float(accurate_labels) / all_labels\n",
    "        print('Test accuracy: {}/{} ({:.3f}%)\\tLoss: {:.6f}'.format(accurate_labels, all_labels, accuracy, loss))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneshot(model, device, data):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(len(data)):\n",
    "            data[i] = data[i].to(device)\n",
    "            \n",
    "        output = model(data)\n",
    "        return torch.squeeze(torch.argmax(output, dim=1)).cpu().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train accuracy: 160796/208274 (77.204%)\n",
      "Test accuracy: 50954/52070 (97.857%)\tLoss: 5.848248\n",
      "Epoch: 1\n",
      "Train accuracy: 168488/208274 (80.897%)\n",
      "Test accuracy: 51168/52070 (98.268%)\tLoss: 4.305115\n",
      "Epoch: 2\n",
      "Train accuracy: 172652/208274 (82.897%)\n",
      "Test accuracy: 51330/52070 (98.579%)\tLoss: 3.260487\n",
      "Epoch: 3\n",
      "Train accuracy: 175962/208274 (84.486%)\n",
      "Test accuracy: 51412/52070 (98.736%)\tLoss: 2.443757\n",
      "Epoch: 4\n",
      "Train accuracy: 177948/208274 (85.439%)\n",
      "Test accuracy: 51474/52070 (98.855%)\tLoss: 2.195866\n",
      "Epoch: 5\n",
      "Train accuracy: 180364/208274 (86.599%)\n",
      "Test accuracy: 51540/52070 (98.982%)\tLoss: 1.792725\n",
      "Epoch: 6\n",
      "Train accuracy: 182408/208274 (87.581%)\n",
      "Test accuracy: 51574/52070 (99.047%)\tLoss: 1.709044\n",
      "Epoch: 7\n",
      "Train accuracy: 183822/208274 (88.260%)\n",
      "Test accuracy: 51608/52070 (99.113%)\tLoss: 1.621768\n",
      "Epoch: 8\n",
      "Train accuracy: 185578/208274 (89.103%)\n",
      "Test accuracy: 51618/52070 (99.132%)\tLoss: 1.624357\n",
      "Epoch: 9\n",
      "Train accuracy: 186886/208274 (89.731%)\n",
      "Test accuracy: 51646/52070 (99.186%)\tLoss: 1.729737\n",
      "Epoch: 10\n",
      "Train accuracy: 188210/208274 (90.367%)\n",
      "Test accuracy: 51654/52070 (99.201%)\tLoss: 1.686567\n",
      "Epoch: 11\n",
      "Train accuracy: 189436/208274 (90.955%)\n",
      "Test accuracy: 51680/52070 (99.251%)\tLoss: 1.600501\n",
      "Epoch: 12\n",
      "Train accuracy: 190508/208274 (91.470%)\n",
      "Test accuracy: 51678/52070 (99.247%)\tLoss: 1.557032\n",
      "Epoch: 13\n",
      "Train accuracy: 191454/208274 (91.924%)\n",
      "Test accuracy: 51682/52070 (99.255%)\tLoss: 1.561596\n",
      "Epoch: 14\n",
      "Train accuracy: 192564/208274 (92.457%)\n",
      "Test accuracy: 51684/52070 (99.259%)\tLoss: 1.472363\n",
      "Epoch: 15\n",
      "Train accuracy: 193150/208274 (92.738%)\n",
      "Test accuracy: 51702/52070 (99.293%)\tLoss: 1.525263\n",
      "Epoch: 16\n",
      "Train accuracy: 194196/208274 (93.241%)\n",
      "Test accuracy: 51706/52070 (99.301%)\tLoss: 1.445565\n",
      "Epoch: 17\n",
      "Train accuracy: 194606/208274 (93.437%)\n",
      "Test accuracy: 51704/52070 (99.297%)\tLoss: 1.435320\n",
      "Epoch: 18\n",
      "Train accuracy: 195394/208274 (93.816%)\n",
      "Test accuracy: 51724/52070 (99.336%)\tLoss: 1.414306\n",
      "Epoch: 19\n",
      "Train accuracy: 196134/208274 (94.171%)\n",
      "Test accuracy: 51704/52070 (99.297%)\tLoss: 1.321402\n",
      "Epoch: 20\n",
      "Train accuracy: 196640/208274 (94.414%)\n",
      "Test accuracy: 51714/52070 (99.316%)\tLoss: 1.277358\n",
      "Epoch: 21\n",
      "Train accuracy: 197110/208274 (94.640%)\n",
      "Test accuracy: 51724/52070 (99.336%)\tLoss: 1.198237\n",
      "Epoch: 22\n",
      "Train accuracy: 197886/208274 (95.012%)\n",
      "Test accuracy: 51732/52070 (99.351%)\tLoss: 1.275626\n",
      "Epoch: 23\n",
      "Train accuracy: 198170/208274 (95.149%)\n",
      "Test accuracy: 51724/52070 (99.336%)\tLoss: 1.303908\n",
      "Epoch: 24\n",
      "Train accuracy: 198702/208274 (95.404%)\n",
      "Test accuracy: 51742/52070 (99.370%)\tLoss: 1.277291\n",
      "Epoch: 25\n",
      "Train accuracy: 198826/208274 (95.464%)\n",
      "Test accuracy: 51742/52070 (99.370%)\tLoss: 1.149428\n",
      "Epoch: 26\n",
      "Train accuracy: 199526/208274 (95.800%)\n",
      "Test accuracy: 51752/52070 (99.389%)\tLoss: 1.032809\n",
      "Epoch: 27\n",
      "Train accuracy: 199710/208274 (95.888%)\n",
      "Test accuracy: 51744/52070 (99.374%)\tLoss: 0.980483\n",
      "Epoch: 28\n",
      "Train accuracy: 200370/208274 (96.205%)\n",
      "Test accuracy: 51748/52070 (99.382%)\tLoss: 0.972682\n",
      "Epoch: 29\n",
      "Train accuracy: 200234/208274 (96.140%)\n",
      "Test accuracy: 51754/52070 (99.393%)\tLoss: 0.949970\n",
      "Epoch: 30\n",
      "Train accuracy: 200892/208274 (96.456%)\n",
      "Test accuracy: 51766/52070 (99.416%)\tLoss: 0.948392\n",
      "Epoch: 31\n",
      "Train accuracy: 200936/208274 (96.477%)\n",
      "Test accuracy: 51756/52070 (99.397%)\tLoss: 1.071975\n",
      "Epoch: 32\n",
      "Train accuracy: 201168/208274 (96.588%)\n",
      "Test accuracy: 51766/52070 (99.416%)\tLoss: 0.927187\n",
      "Epoch: 33\n",
      "Train accuracy: 201474/208274 (96.735%)\n",
      "Test accuracy: 51768/52070 (99.420%)\tLoss: 0.969306\n",
      "Epoch: 34\n",
      "Train accuracy: 201984/208274 (96.980%)\n",
      "Test accuracy: 51760/52070 (99.405%)\tLoss: 0.808750\n",
      "Epoch: 35\n",
      "Train accuracy: 202124/208274 (97.047%)\n",
      "Test accuracy: 51752/52070 (99.389%)\tLoss: 0.862385\n",
      "Epoch: 36\n",
      "Train accuracy: 202390/208274 (97.175%)\n",
      "Test accuracy: 51758/52070 (99.401%)\tLoss: 0.860622\n",
      "Epoch: 37\n",
      "Train accuracy: 202656/208274 (97.303%)\n",
      "Test accuracy: 51756/52070 (99.397%)\tLoss: 0.962226\n",
      "Epoch: 38\n",
      "Train accuracy: 202762/208274 (97.353%)\n",
      "Test accuracy: 51778/52070 (99.439%)\tLoss: 0.876301\n",
      "Epoch: 39\n",
      "Train accuracy: 202932/208274 (97.435%)\n",
      "Test accuracy: 51768/52070 (99.420%)\tLoss: 0.819825\n",
      "Epoch: 40\n",
      "Train accuracy: 203152/208274 (97.541%)\n",
      "Test accuracy: 51774/52070 (99.432%)\tLoss: 0.814962\n",
      "Epoch: 41\n",
      "Train accuracy: 203356/208274 (97.639%)\n",
      "Test accuracy: 51776/52070 (99.435%)\tLoss: 0.763027\n",
      "Epoch: 42\n",
      "Train accuracy: 203454/208274 (97.686%)\n",
      "Test accuracy: 51786/52070 (99.455%)\tLoss: 0.703873\n",
      "Epoch: 43\n",
      "Train accuracy: 203526/208274 (97.720%)\n",
      "Test accuracy: 51774/52070 (99.432%)\tLoss: 0.680118\n",
      "Epoch: 44\n",
      "Train accuracy: 203764/208274 (97.835%)\n",
      "Test accuracy: 51766/52070 (99.416%)\tLoss: 0.669975\n",
      "Epoch: 45\n",
      "Train accuracy: 203796/208274 (97.850%)\n",
      "Test accuracy: 51784/52070 (99.451%)\tLoss: 0.657784\n",
      "Epoch: 46\n",
      "Train accuracy: 204032/208274 (97.963%)\n",
      "Test accuracy: 51768/52070 (99.420%)\tLoss: 0.715569\n",
      "Epoch: 47\n",
      "Train accuracy: 204160/208274 (98.025%)\n",
      "Test accuracy: 51756/52070 (99.397%)\tLoss: 0.659638\n",
      "Epoch: 48\n",
      "Train accuracy: 204436/208274 (98.157%)\n",
      "Test accuracy: 51760/52070 (99.405%)\tLoss: 0.687177\n",
      "Epoch: 49\n",
      "Train accuracy: 204276/208274 (98.080%)\n",
      "Test accuracy: 51770/52070 (99.424%)\tLoss: 0.667167\n",
      "Epoch: 50\n",
      "Train accuracy: 204686/208274 (98.277%)\n",
      "Test accuracy: 51766/52070 (99.416%)\tLoss: 0.762267\n",
      "Epoch: 51\n",
      "Train accuracy: 204758/208274 (98.312%)\n",
      "Test accuracy: 51766/52070 (99.416%)\tLoss: 0.845501\n",
      "Epoch: 52\n",
      "Train accuracy: 204782/208274 (98.323%)\n",
      "Test accuracy: 51758/52070 (99.401%)\tLoss: 0.748617\n",
      "Epoch: 53\n",
      "Train accuracy: 204882/208274 (98.371%)\n",
      "Test accuracy: 51766/52070 (99.416%)\tLoss: 0.758429\n",
      "Epoch: 54\n",
      "Train accuracy: 204956/208274 (98.407%)\n",
      "Test accuracy: 51770/52070 (99.424%)\tLoss: 0.683345\n",
      "Epoch: 55\n",
      "Train accuracy: 205168/208274 (98.509%)\n",
      "Test accuracy: 51756/52070 (99.397%)\tLoss: 0.683298\n",
      "Epoch: 56\n",
      "Train accuracy: 205224/208274 (98.536%)\n",
      "Test accuracy: 51768/52070 (99.420%)\tLoss: 0.626606\n",
      "Epoch: 57\n",
      "Train accuracy: 205172/208274 (98.511%)\n",
      "Test accuracy: 51764/52070 (99.412%)\tLoss: 0.633905\n",
      "Epoch: 58\n",
      "Train accuracy: 205392/208274 (98.616%)\n",
      "Test accuracy: 51770/52070 (99.424%)\tLoss: 0.760836\n",
      "Epoch: 59\n",
      "Train accuracy: 205394/208274 (98.617%)\n",
      "Test accuracy: 51774/52070 (99.432%)\tLoss: 0.695768\n",
      "Epoch: 60\n",
      "Train accuracy: 205464/208274 (98.651%)\n",
      "Test accuracy: 51782/52070 (99.447%)\tLoss: 0.673821\n",
      "Epoch: 61\n",
      "Train accuracy: 205576/208274 (98.705%)\n",
      "Test accuracy: 51776/52070 (99.435%)\tLoss: 0.721039\n",
      "Epoch: 62\n",
      "Train accuracy: 205638/208274 (98.734%)\n",
      "Test accuracy: 51784/52070 (99.451%)\tLoss: 0.715889\n",
      "Epoch: 63\n",
      "Train accuracy: 205772/208274 (98.799%)\n",
      "Test accuracy: 51776/52070 (99.435%)\tLoss: 0.703226\n",
      "Epoch: 64\n",
      "Train accuracy: 205750/208274 (98.788%)\n",
      "Test accuracy: 51772/52070 (99.428%)\tLoss: 0.591372\n",
      "Epoch: 65\n",
      "Train accuracy: 205748/208274 (98.787%)\n",
      "Test accuracy: 51778/52070 (99.439%)\tLoss: 0.647477\n",
      "Epoch: 66\n",
      "Train accuracy: 205916/208274 (98.868%)\n",
      "Test accuracy: 51786/52070 (99.455%)\tLoss: 0.631670\n",
      "Epoch: 67\n",
      "Train accuracy: 205910/208274 (98.865%)\n",
      "Test accuracy: 51790/52070 (99.462%)\tLoss: 0.588814\n",
      "Epoch: 68\n",
      "Train accuracy: 205982/208274 (98.900%)\n",
      "Test accuracy: 51788/52070 (99.458%)\tLoss: 0.572934\n",
      "Epoch: 69\n",
      "Train accuracy: 206020/208274 (98.918%)\n",
      "Test accuracy: 51778/52070 (99.439%)\tLoss: 0.593646\n",
      "Epoch: 70\n",
      "Train accuracy: 206084/208274 (98.949%)\n",
      "Test accuracy: 51784/52070 (99.451%)\tLoss: 0.563658\n",
      "Epoch: 71\n",
      "Train accuracy: 206178/208274 (98.994%)\n",
      "Test accuracy: 51774/52070 (99.432%)\tLoss: 0.472221\n",
      "Epoch: 72\n",
      "Train accuracy: 206224/208274 (99.016%)\n",
      "Test accuracy: 51776/52070 (99.435%)\tLoss: 0.522680\n",
      "Epoch: 73\n",
      "Train accuracy: 206270/208274 (99.038%)\n",
      "Test accuracy: 51790/52070 (99.462%)\tLoss: 0.500965\n",
      "Epoch: 74\n",
      "Train accuracy: 206272/208274 (99.039%)\n",
      "Test accuracy: 51790/52070 (99.462%)\tLoss: 0.498661\n",
      "Epoch: 75\n",
      "Train accuracy: 206284/208274 (99.045%)\n",
      "Test accuracy: 51786/52070 (99.455%)\tLoss: 0.585725\n",
      "Epoch: 76\n",
      "Train accuracy: 206436/208274 (99.118%)\n",
      "Test accuracy: 51796/52070 (99.474%)\tLoss: 0.569342\n",
      "Epoch: 77\n",
      "Train accuracy: 206536/208274 (99.166%)\n",
      "Test accuracy: 51784/52070 (99.451%)\tLoss: 0.582040\n",
      "Epoch: 78\n",
      "Train accuracy: 206404/208274 (99.102%)\n",
      "Test accuracy: 51792/52070 (99.466%)\tLoss: 0.460029\n",
      "Epoch: 79\n",
      "Train accuracy: 206586/208274 (99.190%)\n",
      "Test accuracy: 51786/52070 (99.455%)\tLoss: 0.478103\n",
      "Epoch: 80\n",
      "Train accuracy: 206586/208274 (99.190%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 51794/52070 (99.470%)\tLoss: 0.463919\n",
      "Epoch: 81\n",
      "Train accuracy: 206600/208274 (99.196%)\n",
      "Test accuracy: 51790/52070 (99.462%)\tLoss: 0.388499\n",
      "Epoch: 82\n",
      "Train accuracy: 206690/208274 (99.239%)\n",
      "Test accuracy: 51788/52070 (99.458%)\tLoss: 0.336417\n",
      "Epoch: 83\n",
      "Train accuracy: 206632/208274 (99.212%)\n",
      "Test accuracy: 51800/52070 (99.481%)\tLoss: 0.364311\n",
      "Epoch: 84\n",
      "Train accuracy: 206670/208274 (99.230%)\n",
      "Test accuracy: 51798/52070 (99.478%)\tLoss: 0.318260\n",
      "Epoch: 85\n",
      "Train accuracy: 206752/208274 (99.269%)\n",
      "Test accuracy: 51790/52070 (99.462%)\tLoss: 0.360947\n",
      "Epoch: 86\n",
      "Train accuracy: 206710/208274 (99.249%)\n",
      "Test accuracy: 51796/52070 (99.474%)\tLoss: 0.413306\n",
      "Epoch: 87\n",
      "Train accuracy: 206792/208274 (99.288%)\n",
      "Test accuracy: 51796/52070 (99.474%)\tLoss: 0.385740\n",
      "Epoch: 88\n",
      "Train accuracy: 206752/208274 (99.269%)\n",
      "Test accuracy: 51792/52070 (99.466%)\tLoss: 0.360173\n",
      "Epoch: 89\n",
      "Train accuracy: 206902/208274 (99.341%)\n",
      "Test accuracy: 51800/52070 (99.481%)\tLoss: 0.382068\n",
      "Epoch: 90\n",
      "Train accuracy: 206874/208274 (99.328%)\n",
      "Test accuracy: 51806/52070 (99.493%)\tLoss: 0.418416\n",
      "Epoch: 91\n",
      "Train accuracy: 206858/208274 (99.320%)\n",
      "Test accuracy: 51792/52070 (99.466%)\tLoss: 0.485820\n",
      "Epoch: 92\n",
      "Train accuracy: 206946/208274 (99.362%)\n",
      "Test accuracy: 51792/52070 (99.466%)\tLoss: 0.384464\n",
      "Epoch: 93\n",
      "Train accuracy: 207058/208274 (99.416%)\n",
      "Test accuracy: 51792/52070 (99.466%)\tLoss: 0.419562\n",
      "Epoch: 94\n",
      "Train accuracy: 207036/208274 (99.406%)\n",
      "Test accuracy: 51800/52070 (99.481%)\tLoss: 0.347341\n",
      "Epoch: 95\n",
      "Train accuracy: 206964/208274 (99.371%)\n",
      "Test accuracy: 51814/52070 (99.508%)\tLoss: 0.347220\n",
      "Epoch: 96\n",
      "Train accuracy: 207014/208274 (99.395%)\n",
      "Test accuracy: 51806/52070 (99.493%)\tLoss: 0.325534\n",
      "Epoch: 97\n",
      "Train accuracy: 207052/208274 (99.413%)\n",
      "Test accuracy: 51814/52070 (99.508%)\tLoss: 0.340878\n",
      "Epoch: 98\n",
      "Train accuracy: 207148/208274 (99.459%)\n",
      "Test accuracy: 51806/52070 (99.493%)\tLoss: 0.417956\n",
      "Epoch: 99\n",
      "Train accuracy: 207192/208274 (99.480%)\n",
      "Test accuracy: 51796/52070 (99.474%)\tLoss: 0.361430\n",
      "Epoch: 100\n",
      "Train accuracy: 207138/208274 (99.455%)\n",
      "Test accuracy: 51792/52070 (99.466%)\tLoss: 0.448094\n",
      "Epoch: 101\n",
      "Train accuracy: 207202/208274 (99.485%)\n",
      "Test accuracy: 51802/52070 (99.485%)\tLoss: 0.461236\n",
      "Epoch: 102\n",
      "Train accuracy: 207092/208274 (99.432%)\n",
      "Test accuracy: 51790/52070 (99.462%)\tLoss: 0.514652\n",
      "Epoch: 103\n",
      "Train accuracy: 207180/208274 (99.475%)\n",
      "Test accuracy: 51792/52070 (99.466%)\tLoss: 0.438884\n",
      "Epoch: 104\n",
      "Train accuracy: 207214/208274 (99.491%)\n",
      "Test accuracy: 51790/52070 (99.462%)\tLoss: 0.350420\n",
      "Epoch: 105\n",
      "Train accuracy: 207226/208274 (99.497%)\n",
      "Test accuracy: 51802/52070 (99.485%)\tLoss: 0.384408\n",
      "Epoch: 106\n",
      "Train accuracy: 207266/208274 (99.516%)\n",
      "Test accuracy: 51790/52070 (99.462%)\tLoss: 0.343280\n",
      "Epoch: 107\n",
      "Train accuracy: 207270/208274 (99.518%)\n",
      "Test accuracy: 51792/52070 (99.466%)\tLoss: 0.393444\n",
      "Epoch: 108\n",
      "Train accuracy: 207310/208274 (99.537%)\n",
      "Test accuracy: 51796/52070 (99.474%)\tLoss: 0.429101\n",
      "Epoch: 109\n",
      "Train accuracy: 207264/208274 (99.515%)\n",
      "Test accuracy: 51794/52070 (99.470%)\tLoss: 0.422127\n",
      "Epoch: 110\n",
      "Train accuracy: 207324/208274 (99.544%)\n",
      "Test accuracy: 51796/52070 (99.474%)\tLoss: 0.338048\n",
      "Epoch: 111\n",
      "Train accuracy: 207386/208274 (99.574%)\n",
      "Test accuracy: 51800/52070 (99.481%)\tLoss: 0.361410\n",
      "Epoch: 112\n",
      "Train accuracy: 207360/208274 (99.561%)\n",
      "Test accuracy: 51800/52070 (99.481%)\tLoss: 0.315158\n",
      "Epoch: 113\n",
      "Train accuracy: 207438/208274 (99.599%)\n",
      "Test accuracy: 51806/52070 (99.493%)\tLoss: 0.301280\n",
      "Epoch: 114\n",
      "Train accuracy: 207360/208274 (99.561%)\n",
      "Test accuracy: 51802/52070 (99.485%)\tLoss: 0.336611\n",
      "Epoch: 115\n",
      "Train accuracy: 207392/208274 (99.577%)\n",
      "Test accuracy: 51794/52070 (99.470%)\tLoss: 0.307727\n",
      "Epoch: 116\n",
      "Train accuracy: 207424/208274 (99.592%)\n",
      "Test accuracy: 51804/52070 (99.489%)\tLoss: 0.335568\n",
      "Epoch: 117\n",
      "Train accuracy: 207492/208274 (99.625%)\n",
      "Test accuracy: 51794/52070 (99.470%)\tLoss: 0.228595\n",
      "Epoch: 118\n",
      "Train accuracy: 207430/208274 (99.595%)\n",
      "Test accuracy: 51788/52070 (99.458%)\tLoss: 0.316585\n",
      "Epoch: 119\n",
      "Train accuracy: 207424/208274 (99.592%)\n",
      "Test accuracy: 51796/52070 (99.474%)\tLoss: 0.350414\n",
      "Epoch: 120\n",
      "Train accuracy: 207468/208274 (99.613%)\n",
      "Test accuracy: 51806/52070 (99.493%)\tLoss: 0.389919\n",
      "Epoch: 121\n",
      "Train accuracy: 207514/208274 (99.635%)\n",
      "Test accuracy: 51804/52070 (99.489%)\tLoss: 0.382618\n",
      "Epoch: 122\n",
      "Train accuracy: 207520/208274 (99.638%)\n",
      "Test accuracy: 51790/52070 (99.462%)\tLoss: 0.343775\n",
      "Epoch: 123\n",
      "Train accuracy: 207506/208274 (99.631%)\n",
      "Test accuracy: 51820/52070 (99.520%)\tLoss: 0.382696\n",
      "Epoch: 124\n",
      "Train accuracy: 207528/208274 (99.642%)\n",
      "Test accuracy: 51806/52070 (99.493%)\tLoss: 0.347507\n",
      "Epoch: 125\n",
      "Train accuracy: 207490/208274 (99.624%)\n",
      "Test accuracy: 51794/52070 (99.470%)\tLoss: 0.451580\n",
      "Epoch: 126\n",
      "Train accuracy: 207542/208274 (99.649%)\n",
      "Test accuracy: 51810/52070 (99.501%)\tLoss: 0.506289\n",
      "Epoch: 127\n",
      "Train accuracy: 207490/208274 (99.624%)\n",
      "Test accuracy: 51794/52070 (99.470%)\tLoss: 0.462133\n",
      "Epoch: 128\n",
      "Train accuracy: 207570/208274 (99.662%)\n",
      "Test accuracy: 51796/52070 (99.474%)\tLoss: 0.532000\n",
      "Epoch: 129\n",
      "Train accuracy: 207582/208274 (99.668%)\n",
      "Test accuracy: 51794/52070 (99.470%)\tLoss: 0.531949\n",
      "Epoch: 130\n",
      "Train accuracy: 207618/208274 (99.685%)\n",
      "Test accuracy: 51794/52070 (99.470%)\tLoss: 0.627583\n",
      "Epoch: 131\n",
      "Train accuracy: 207598/208274 (99.675%)\n",
      "Test accuracy: 51786/52070 (99.455%)\tLoss: 0.603908\n",
      "Epoch: 132\n",
      "Train accuracy: 207638/208274 (99.695%)\n",
      "Test accuracy: 51792/52070 (99.466%)\tLoss: 0.541130\n",
      "Epoch: 133\n",
      "Train accuracy: 207578/208274 (99.666%)\n",
      "Test accuracy: 51802/52070 (99.485%)\tLoss: 0.540929\n",
      "Epoch: 134\n",
      "Train accuracy: 207664/208274 (99.707%)\n",
      "Test accuracy: 51804/52070 (99.489%)\tLoss: 0.381358\n",
      "Epoch: 135\n",
      "Train accuracy: 207612/208274 (99.682%)\n",
      "Test accuracy: 51804/52070 (99.489%)\tLoss: 0.419268\n",
      "Epoch: 136\n",
      "Train accuracy: 207550/208274 (99.652%)\n",
      "Test accuracy: 51790/52070 (99.462%)\tLoss: 0.550421\n",
      "Epoch: 137\n",
      "Train accuracy: 207614/208274 (99.683%)\n",
      "Test accuracy: 51786/52070 (99.455%)\tLoss: 0.603501\n",
      "Epoch: 138\n",
      "Train accuracy: 207640/208274 (99.696%)\n",
      "Test accuracy: 51796/52070 (99.474%)\tLoss: 0.550044\n",
      "Epoch: 139\n",
      "Train accuracy: 207628/208274 (99.690%)\n",
      "Test accuracy: 51790/52070 (99.462%)\tLoss: 0.641432\n",
      "Epoch: 140\n",
      "Train accuracy: 207636/208274 (99.694%)\n",
      "Test accuracy: 51806/52070 (99.493%)\tLoss: 0.514240\n",
      "Epoch: 141\n",
      "Train accuracy: 207668/208274 (99.709%)\n",
      "Test accuracy: 51796/52070 (99.474%)\tLoss: 0.373324\n",
      "Epoch: 142\n",
      "Train accuracy: 207710/208274 (99.729%)\n",
      "Test accuracy: 51808/52070 (99.497%)\tLoss: 0.354306\n",
      "Epoch: 143\n",
      "Train accuracy: 207688/208274 (99.719%)\n",
      "Test accuracy: 51810/52070 (99.501%)\tLoss: 0.352233\n",
      "Epoch: 144\n",
      "Train accuracy: 207722/208274 (99.735%)\n",
      "Test accuracy: 51804/52070 (99.489%)\tLoss: 0.407224\n",
      "Epoch: 145\n",
      "Train accuracy: 207704/208274 (99.726%)\n",
      "Test accuracy: 51786/52070 (99.455%)\tLoss: 0.398444\n",
      "Epoch: 146\n",
      "Train accuracy: 207752/208274 (99.749%)\n",
      "Test accuracy: 51794/52070 (99.470%)\tLoss: 0.388413\n",
      "Epoch: 147\n",
      "Train accuracy: 207696/208274 (99.722%)\n",
      "Test accuracy: 51788/52070 (99.458%)\tLoss: 0.459144\n",
      "Epoch: 148\n",
      "Train accuracy: 207696/208274 (99.722%)\n",
      "Test accuracy: 51792/52070 (99.466%)\tLoss: 0.461348\n",
      "Epoch: 149\n",
      "Train accuracy: 207698/208274 (99.723%)\n",
      "Test accuracy: 51788/52070 (99.458%)\tLoss: 0.371630\n",
      "Epoch: 150\n",
      "Train accuracy: 207742/208274 (99.745%)\n",
      "Test accuracy: 51788/52070 (99.458%)\tLoss: 0.383622\n",
      "Epoch: 151\n",
      "Train accuracy: 207724/208274 (99.736%)\n",
      "Test accuracy: 51784/52070 (99.451%)\tLoss: 0.374645\n",
      "Epoch: 152\n",
      "Train accuracy: 207772/208274 (99.759%)\n",
      "Test accuracy: 51786/52070 (99.455%)\tLoss: 0.319494\n",
      "Epoch: 153\n",
      "Train accuracy: 207692/208274 (99.721%)\n",
      "Test accuracy: 51784/52070 (99.451%)\tLoss: 0.387560\n",
      "Epoch: 154\n",
      "Train accuracy: 207734/208274 (99.741%)\n",
      "Test accuracy: 51790/52070 (99.462%)\tLoss: 0.346604\n",
      "Epoch: 155\n",
      "Train accuracy: 207778/208274 (99.762%)\n",
      "Test accuracy: 51782/52070 (99.447%)\tLoss: 0.399415\n",
      "Epoch: 156\n",
      "Train accuracy: 207746/208274 (99.746%)\n",
      "Test accuracy: 51784/52070 (99.451%)\tLoss: 0.403255\n",
      "Epoch: 157\n",
      "Train accuracy: 207716/208274 (99.732%)\n",
      "Test accuracy: 51784/52070 (99.451%)\tLoss: 0.329350\n",
      "Epoch: 158\n",
      "Train accuracy: 207764/208274 (99.755%)\n",
      "Test accuracy: 51788/52070 (99.458%)\tLoss: 0.358780\n",
      "Epoch: 159\n",
      "Train accuracy: 207778/208274 (99.762%)\n",
      "Test accuracy: 51804/52070 (99.489%)\tLoss: 0.357188\n",
      "Epoch: 160\n",
      "Train accuracy: 207766/208274 (99.756%)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 51800/52070 (99.481%)\tLoss: 0.395726\n",
      "Epoch: 161\n",
      "Train accuracy: 207818/208274 (99.781%)\n",
      "Test accuracy: 51804/52070 (99.489%)\tLoss: 0.369237\n",
      "Epoch: 162\n",
      "Train accuracy: 207730/208274 (99.739%)\n",
      "Test accuracy: 51806/52070 (99.493%)\tLoss: 0.409520\n",
      "Epoch: 163\n",
      "Train accuracy: 207800/208274 (99.772%)\n",
      "Test accuracy: 51788/52070 (99.458%)\tLoss: 0.429564\n",
      "Epoch: 164\n",
      "Train accuracy: 207780/208274 (99.763%)\n",
      "Test accuracy: 51794/52070 (99.470%)\tLoss: 0.372151\n",
      "Epoch: 165\n",
      "Train accuracy: 207894/208274 (99.818%)\n",
      "Test accuracy: 51798/52070 (99.478%)\tLoss: 0.353778\n",
      "Epoch: 166\n",
      "Train accuracy: 207792/208274 (99.769%)\n",
      "Test accuracy: 51792/52070 (99.466%)\tLoss: 0.350045\n",
      "Epoch: 167\n",
      "Train accuracy: 207754/208274 (99.750%)\n",
      "Test accuracy: 51796/52070 (99.474%)\tLoss: 0.364595\n",
      "Epoch: 168\n",
      "Train accuracy: 207828/208274 (99.786%)\n",
      "Test accuracy: 51800/52070 (99.481%)\tLoss: 0.329694\n",
      "Epoch: 169\n",
      "Train accuracy: 207840/208274 (99.792%)\n",
      "Test accuracy: 51788/52070 (99.458%)\tLoss: 0.298722\n",
      "Epoch: 170\n",
      "Train accuracy: 207810/208274 (99.777%)\n",
      "Test accuracy: 51784/52070 (99.451%)\tLoss: 0.321034\n",
      "Epoch: 171\n",
      "Train accuracy: 207790/208274 (99.768%)\n",
      "Test accuracy: 51788/52070 (99.458%)\tLoss: 0.309801\n",
      "Epoch: 172\n",
      "Train accuracy: 207836/208274 (99.790%)\n",
      "Test accuracy: 51790/52070 (99.462%)\tLoss: 0.240121\n",
      "Epoch: 173\n",
      "Train accuracy: 207808/208274 (99.776%)\n",
      "Test accuracy: 51784/52070 (99.451%)\tLoss: 0.241792\n",
      "Epoch: 174\n",
      "Train accuracy: 207882/208274 (99.812%)\n",
      "Test accuracy: 51786/52070 (99.455%)\tLoss: 0.262746\n",
      "Epoch: 175\n",
      "Train accuracy: 207888/208274 (99.815%)\n",
      "Test accuracy: 51778/52070 (99.439%)\tLoss: 0.200492\n",
      "Epoch: 176\n",
      "Train accuracy: 207874/208274 (99.808%)\n",
      "Test accuracy: 51786/52070 (99.455%)\tLoss: 0.226237\n",
      "Epoch: 177\n",
      "Train accuracy: 207792/208274 (99.769%)\n",
      "Test accuracy: 51794/52070 (99.470%)\tLoss: 0.301524\n",
      "Epoch: 178\n",
      "Train accuracy: 207904/208274 (99.822%)\n",
      "Test accuracy: 51796/52070 (99.474%)\tLoss: 0.397065\n",
      "Epoch: 179\n",
      "Train accuracy: 207896/208274 (99.819%)\n",
      "Test accuracy: 51794/52070 (99.470%)\tLoss: 0.346622\n",
      "Epoch: 180\n",
      "Train accuracy: 207934/208274 (99.837%)\n",
      "Test accuracy: 51798/52070 (99.478%)\tLoss: 0.305631\n",
      "Epoch: 181\n",
      "Train accuracy: 207886/208274 (99.814%)\n",
      "Test accuracy: 51788/52070 (99.458%)\tLoss: 0.319593\n",
      "Epoch: 182\n",
      "Train accuracy: 207954/208274 (99.846%)\n",
      "Test accuracy: 51780/52070 (99.443%)\tLoss: 0.227083\n",
      "Epoch: 183\n",
      "Train accuracy: 207866/208274 (99.804%)\n",
      "Test accuracy: 51780/52070 (99.443%)\tLoss: 0.344120\n",
      "Epoch: 184\n",
      "Train accuracy: 207898/208274 (99.819%)\n",
      "Test accuracy: 51784/52070 (99.451%)\tLoss: 0.417310\n",
      "Epoch: 185\n",
      "Train accuracy: 207884/208274 (99.813%)\n",
      "Test accuracy: 51790/52070 (99.462%)\tLoss: 0.351197\n",
      "Epoch: 186\n",
      "Train accuracy: 207880/208274 (99.811%)\n",
      "Test accuracy: 51784/52070 (99.451%)\tLoss: 0.347165\n",
      "Epoch: 187\n",
      "Train accuracy: 207892/208274 (99.817%)\n",
      "Test accuracy: 51806/52070 (99.493%)\tLoss: 0.345606\n",
      "Epoch: 188\n",
      "Train accuracy: 207874/208274 (99.808%)\n",
      "Test accuracy: 51776/52070 (99.435%)\tLoss: 0.427793\n",
      "Epoch: 189\n",
      "Train accuracy: 207888/208274 (99.815%)\n",
      "Test accuracy: 51796/52070 (99.474%)\tLoss: 0.380090\n",
      "Epoch: 190\n",
      "Train accuracy: 207900/208274 (99.820%)\n",
      "Test accuracy: 51786/52070 (99.455%)\tLoss: 0.450084\n",
      "Epoch: 191\n",
      "Train accuracy: 207916/208274 (99.828%)\n",
      "Test accuracy: 51796/52070 (99.474%)\tLoss: 0.426245\n",
      "Epoch: 192\n",
      "Train accuracy: 207894/208274 (99.818%)\n",
      "Test accuracy: 51792/52070 (99.466%)\tLoss: 0.377369\n",
      "Epoch: 193\n",
      "Train accuracy: 207942/208274 (99.841%)\n",
      "Test accuracy: 51784/52070 (99.451%)\tLoss: 0.401390\n",
      "Epoch: 194\n",
      "Train accuracy: 207938/208274 (99.839%)\n",
      "Test accuracy: 51784/52070 (99.451%)\tLoss: 0.316424\n",
      "Epoch: 195\n",
      "Train accuracy: 207932/208274 (99.836%)\n",
      "Test accuracy: 51788/52070 (99.458%)\tLoss: 0.399014\n",
      "Epoch: 196\n",
      "Train accuracy: 207954/208274 (99.846%)\n",
      "Test accuracy: 51798/52070 (99.478%)\tLoss: 0.334510\n",
      "Epoch: 197\n",
      "Train accuracy: 207936/208274 (99.838%)\n",
      "Test accuracy: 51800/52070 (99.481%)\tLoss: 0.290863\n",
      "Epoch: 198\n",
      "Train accuracy: 207946/208274 (99.843%)\n",
      "Test accuracy: 51800/52070 (99.481%)\tLoss: 0.305227\n",
      "Epoch: 199\n",
      "Train accuracy: 207948/208274 (99.843%)\n",
      "Test accuracy: 51798/52070 (99.478%)\tLoss: 0.300016\n"
     ]
    }
   ],
   "source": [
    "trans = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (1.0,))])\n",
    "\n",
    "model = Net().to(device)\n",
    "   \n",
    "if do_learn: # training mode\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    #optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "    for epoch in range(num_epochs):\n",
    "        train(model, device, train_loader, epoch, optimizer)\n",
    "        test(model, device, test_loader)\n",
    "        #if epoch & save_frequency == 0:\n",
    "            #torch.save(model, 'siamese_{:03}.pt'.format(epoch))\n",
    "        #else: # prediction\n",
    "        #    prediction_loader = torch.utils.data.DataLoader(BalancedMNISTPair(\n",
    "        #        '../data', train=False, download=True, transform=trans), batch_size=1, shuffle=True)\n",
    "        #    model.load_state_dict(torch.load(load_model_path))\n",
    "        #    data = []\n",
    "        #    data.extend(next(iter(prediction_loader))[0][:3:2])\n",
    "        #    same = oneshot(model, device, data)\n",
    "        #    if same > 0:\n",
    "        #        print('These two images are of the same number')\n",
    "        #    else:\n",
    "        #        print('These two images are not of the same number')\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model, 'siamese99.1%modsworking.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove modifications\n",
    "use one charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0836, -0.2683, -2.6547],\n",
      "        [-0.4704, -0.8377,  1.3105],\n",
      "        [ 0.8315,  0.1661, -0.5774],\n",
      "        [-0.8142,  0.5784, -1.6145]])\n",
      "tensor([[ 0.0313, -0.1005, -0.9944],\n",
      "        [-0.2895, -0.5155,  0.8065],\n",
      "        [ 0.8105,  0.1619, -0.5629],\n",
      "        [-0.4289,  0.3047, -0.8504]])\n",
      "tensor(1.0000)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn((4, 3))\n",
    "print(x)\n",
    "x = F.normalize(x)\n",
    "print(x)\n",
    "print(torch.sqrt(torch.sum(x[0]**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
