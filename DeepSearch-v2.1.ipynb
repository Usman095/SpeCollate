{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "import numpy as np\n",
    "import random as rand\n",
    "import queue\n",
    "import csv\n",
    "from collections import OrderedDict\n",
    "from IPython.display import clear_output\n",
    "import csv\n",
    "import re\n",
    "from heapq import merge\n",
    "from sklearn import preprocessing\n",
    "from operator import itemgetter\n",
    "import bisect\n",
    "import pickle\n",
    "import os\n",
    "from configparser import ConfigParser\n",
    "import ast\n",
    "import sys\n",
    "\n",
    "from sklearn.datasets import make_circles, make_moons\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from IPython.core.debugger import set_trace\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "from IPython.display import display\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "from src.snapprocess import simulatespectra as sim\n",
    "from src.snapprocess import process\n",
    "from src.snaputils import reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary config func. Original one in the project.\n",
    "class config:\n",
    "    \"\"\"Define constants\"\"\"\n",
    "    AAMass = {'A': 71.037114, 'C': 103.009185, 'D': 115.026943, 'E': 129.042593, 'F': 147.068414, 'G': 57.021464,\n",
    "              'H': 137.058912, 'I': 113.084064, 'K': 128.094963, 'L': 113.084064, 'M': 131.040485, 'N': 114.042927,\n",
    "              'P': 97.052764, 'Q': 128.058578, 'R': 156.101111, 'S': 87.032028, 'T': 101.047679, 'V': 99.068414,\n",
    "              'W': 186.079313, 'Y': 163.0633}\n",
    "\n",
    "    H2O = 18.015\n",
    "    NH3 = 17.031\n",
    "    PROTON = 1.00727647\n",
    "    DEFAULT_PARAM_PATH = os.path.join(os.getcwd(), 'config.ini')\n",
    "    PARAM_PATH = None\n",
    "    l_config = None\n",
    "\n",
    "\n",
    "    def get_config(section='input', key=None):\n",
    "        \"\"\"Read the configuration parameters and return a dictionary.\"\"\"\n",
    "\n",
    "        # If file path is given use it otherwise use default.\n",
    "        file_path = config.PARAM_PATH if config.PARAM_PATH else config.DEFAULT_PARAM_PATH\n",
    "\n",
    "        # Read config and convert each value to appropriate type.\n",
    "        # Only for the first time.\n",
    "        if not config.l_config:\n",
    "            config.l_config = dict()\n",
    "            config_ = ConfigParser()\n",
    "            assert isinstance(file_path, str)\n",
    "            config_.read(file_path)\n",
    "            for section_ in config_.sections():\n",
    "                config.l_config[section_] = dict()\n",
    "                for key_ in config_[section_]:\n",
    "                    try:\n",
    "                        config.l_config[section_][key_] = ast.literal_eval(config_[section_][key_])\n",
    "                    except (ValueError, SyntaxError):\n",
    "                        config.l_config[section_][key_] = config_[section_][key_]\n",
    "\n",
    "        if section and section in config.l_config:\n",
    "            if key and key in config.l_config[section]:\n",
    "                return config.l_config[section][key]\n",
    "            return config.l_config[section]\n",
    "        return config.l_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "False\n",
      "2048\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(config.get_config(section='input', key='charge'))\n",
    "print(config.get_config(section='input', key='use_mods'))\n",
    "print(config.get_config(section='ml', key='batch_size'))\n",
    "print(config.get_config(section='input', key='num_species'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.spec_size = config.get_config(section='input', key='spec_size')\n",
    "        self.searching = False\n",
    "        \n",
    "        self.linear1_1 = nn.Linear(self.spec_size, 1024)\n",
    "        self.linear1_2 = nn.Linear(1024, 512)\n",
    "        self.linear1_3 = nn.Linear(512, 256)\n",
    "        \n",
    "        self.linear2_1 = nn.Linear(self.spec_size, 1024)\n",
    "        self.linear2_2 = nn.Linear(1024, 512)\n",
    "        self.linear2_3 = nn.Linear(512, 256)\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        #self.dropout3 = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        res = []\n",
    "#         x = data[:, 0]\n",
    "#         x = self.linear1_1(x.view(-1, self.spec_size))\n",
    "#         x = F.relu(x)\n",
    "#         x = self.dropout2(x)\n",
    "        #x = self.linear1_2(x)\n",
    "        #x = F.relu(x)\n",
    "        #x = self.dropout2(x)\n",
    "        #x = self.dropout2(x)\n",
    "        #x = self.linear1_3(x)\n",
    "        #x = F.relu(x)\n",
    "        #if not self.searching:\n",
    "        #    x = F.normalize(x)\n",
    "        #res.append(x)\n",
    "        for i in range(data.shape[1]):\n",
    "            x = data[:, i]\n",
    "            x = self.linear2_1(x.view(-1, self.spec_size))\n",
    "            x = F.relu(x)\n",
    "            #x = torch.tanh(x)\n",
    "            x = self.dropout1(x)\n",
    "            x = self.linear2_2(x)\n",
    "            x = F.relu(x)\n",
    "            #x = torch.tanh(x)\n",
    "            #x = self.dropout2(x)\n",
    "            #x = self.dropout1(x)\n",
    "            #x = self.linear2_3(x)\n",
    "            #x = F.relu(x)\n",
    "            #if not self.searching:\n",
    "            x = F.normalize(x)\n",
    "            #x = self.linear1_3(x)\n",
    "            #x = F.relu(x)\n",
    "            res.append(x)\n",
    "        \n",
    "        return res\n",
    "    \n",
    "    def name(self):\n",
    "        return \"Net\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand.seed(37)\n",
    "\n",
    "config.AAMass\n",
    "H2O = 18.01528\n",
    "PROTON = 1.00727647\n",
    "\n",
    "specsize = 8000\n",
    "precursor_tolerance = 3.0\n",
    "num_psm = 1\n",
    "charge = 2\n",
    "use_mods = False\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "batch_size = config.get_config(section='ml', key='batch_size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (linear1_1): Linear(in_features=8000, out_features=1024, bias=True)\n",
       "  (linear1_2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (linear1_3): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (linear2_1): Linear(in_features=8000, out_features=1024, bias=True)\n",
       "  (linear2_2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (linear2_3): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (dropout1): Dropout(p=0.5, inplace=False)\n",
       "  (dropout2): Dropout(p=0.3, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.load('models/hard_triplet_98.1%_charge_multi-specie.pt').to(device)\n",
    "model.eval()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runModel(loader):\n",
    "    with torch.no_grad():\n",
    "        accurate_labels = 0\n",
    "        all_labels = 0\n",
    "        loss = 0\n",
    "        out = torch.Tensor().to(device)\n",
    "        for batch_idx, data in enumerate(loader):\n",
    "            data = data.to(device)    \n",
    "            out = torch.cat((out, model(data)[0]), dim=0)\n",
    "    print(out.size())\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readmgfs(folderPath, charge=None):\n",
    "    \n",
    "    mgffiles = [f for f in listdir(folderPath) if isfile(join(folderPath, f)) and f.split('.')[-1] == 'mgf']\n",
    "    assert len(mgffiles) > 0\n",
    "    \n",
    "    spectra = []\n",
    "    masses = []\n",
    "    charges = []\n",
    "    for file in mgffiles:\n",
    "        f = open(join(folderPath, file))\n",
    "        speclines = f.readlines()\n",
    "        f.close()\n",
    "        \n",
    "        if not speclines:\n",
    "            continue\n",
    "            \n",
    "        spec = np.zeros(specsize)\n",
    "        isMass = isCharge = isSpec = False\n",
    "        i = 0\n",
    "        '''Read Headers'''\n",
    "        while True:\n",
    "            line = speclines[i]\n",
    "            i += 1\n",
    "            \n",
    "            splits = line.split('=')\n",
    "            if splits[0].upper() == 'PEPMASS':\n",
    "                masses.append(float(splits[1].split(' ')[0]))\n",
    "                isMass = True\n",
    "                \n",
    "            if isMass and splits[0].upper() == 'CHARGE':\n",
    "                l_charge = int(splits[1][0])\n",
    "                if charge and l_charge != charge:\n",
    "                    del masses[-1]\n",
    "                    isMass = False\n",
    "                    isCharge = False\n",
    "                else:\n",
    "                    charges.append(l_charge)\n",
    "                    isCharge = True\n",
    "                break\n",
    "        \n",
    "        '''Read Spectrum'''\n",
    "        while isMass and isCharge and i < len(speclines):\n",
    "            line = speclines[i]\n",
    "            i += 1\n",
    "            \n",
    "            if line != '\\n' and 'END IONS' not in line.upper():\n",
    "                splits = line.split(' ')\n",
    "                moz, intensity = float(splits[0]), float(splits[1])\n",
    "                spec[round(moz)] += round(intensity)\n",
    "            elif 'END IONS' in line.upper():\n",
    "                break\n",
    "                \n",
    "        if isMass and isCharge:        \n",
    "            spec = np.clip(spec, None, 1000.0)\n",
    "            spec = preprocessing.scale(spec)\n",
    "            spectra.append(spec)\n",
    "        \n",
    "    return spectra, masses, charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readms2(file, charge=None):\n",
    "    f = open(file)\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "    \n",
    "    spectra = []\n",
    "    masses = []\n",
    "    charges = []\n",
    "    i = 0\n",
    "    while i < len(lines):\n",
    "        line = lines[i][:-1]\n",
    "        i += 1\n",
    "        \n",
    "        splits = line.split('\\t')\n",
    "        if splits[0] == 'Z' and (charge is None or float(splits[1]) == charge):\n",
    "            charges.append(float(splits[1]))\n",
    "            masses.append(float(splits[2]))\n",
    "            spec = np.zeros(specsize)\n",
    "            while i < len(lines):\n",
    "                line = lines[i][:-1] #remove the \\n character\n",
    "                i += 1\n",
    "                splits = line.split(' ')\n",
    "                if 'S' in splits[0]:\n",
    "                    break\n",
    "                if 'Z' in splits[0]:\n",
    "                    continue\n",
    "                moz, intensity = float(splits[0]), float(splits[1])\n",
    "                spec[round(moz)] += round(intensity)\n",
    "            \n",
    "            spec = np.clip(spec, None, 1000.0)\n",
    "            spec = preprocessing.scale(spec)\n",
    "            spectra.append(spec)\n",
    "            \n",
    "    return spectra, masses, charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([150, 512])\n"
     ]
    }
   ],
   "source": [
    "ms2file = '/disk/raptor/lclhome/mtari008/Proteomics/crux/specs/demo.ms2'\n",
    "\n",
    "#queryspectra, spectramasses, _ = readmgfs(specsPath, charge=2)\n",
    "queryspectra, spectramasses, _ = readms2(ms2file, None)\n",
    "with torch.no_grad():\n",
    "    queryspectraTensor = torch.tensor(queryspectra, dtype=torch.float)[:, None, :]\n",
    "    queryspectra_loader = torch.utils.data.DataLoader(dataset=queryspectraTensor, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    queryspectra_out = runModel(queryspectra_loader)\n",
    "del queryspectraTensor\n",
    "del queryspectra_loader\n",
    "del queryspectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "print(type(queryspectra_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n"
     ]
    }
   ],
   "source": [
    "print(batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fastatospectra(lines, start, count, dh):\n",
    "    tspectra = []\n",
    "    masses = []\n",
    "    peps = []\n",
    "    \n",
    "    new = prev = 0\n",
    "    end = min(start+count, len(lines))\n",
    "    for i, line in enumerate(lines[start:end]):\n",
    "        splits = line.split('\\t')\n",
    "        \n",
    "        pep = splits[0]\n",
    "        #print(pep)\n",
    "        peps.append(pep)\n",
    "        spec = sim.get_spectrum(pep)\n",
    "        tspectra.append(preprocessing.scale(spec))\n",
    "        masses.append(float(splits[1]))\n",
    "        \n",
    "        #print(splits[1])\n",
    "        '''Progress Monitor'''\n",
    "        new = int(((i+start)/len(lines)) * 100)\n",
    "        if (new > prev):\n",
    "            dh.update(str(new)+'%')\n",
    "            prev = new\n",
    "            \n",
    "    return tspectra, masses, peps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fastaToSpectraBatch(filePath, spectra_batch_size):    \n",
    "    f = open(filePath)\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "    masses = []\n",
    "    spectra_out = torch.Tensor().to(device)\n",
    "    peps = []\n",
    "    \n",
    "    dh = display('0%', display_id=True)\n",
    "    \n",
    "    start = 0\n",
    "    i = 0\n",
    "    while start < len(lines):\n",
    "        print('Batch: ' + str(i))\n",
    "        i += 1\n",
    "        \n",
    "        print('Generating spectra...')\n",
    "        spectra, l_masses, l_peps = fastatospectra(lines, start, spectra_batch_size, dh)\n",
    "        masses.extend(l_masses)\n",
    "        peps.extend(l_peps)\n",
    "        start = start + spectra_batch_size\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            print('Converting to tensor...')\n",
    "            '''dtype=torch.float'''\n",
    "            spectra = np.asarray(spectra)\n",
    "            spectraTensor = torch.as_tensor(spectra, dtype=torch.float)[:, None, :]\n",
    "            spectra_loader = torch.utils.data.DataLoader(dataset=spectraTensor, batch_size=batch_size, shuffle=False)\n",
    "            \n",
    "            print('Running the model...')\n",
    "            model_out = runModel(spectra_loader)\n",
    "            spectra_out = torch.cat((spectra_out, model_out), dim=0)\n",
    "            \n",
    "    return spectra_out, masses, peps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'99%'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0\n",
      "Generating spectra...\n",
      "Converting to tensor...\n",
      "Running the model...\n",
      "torch.Size([7103, 512])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'99%'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0\n",
      "Generating spectra...\n",
      "Converting to tensor...\n",
      "Running the model...\n",
      "torch.Size([7103, 512])\n",
      "7103 7103\n",
      "7103 7103\n"
     ]
    }
   ],
   "source": [
    "spectra_batch_size = 500000\n",
    "#targetPath = '/disk/raptor/lclhome/mtari008/Proteogenomics/DeepSNAP/data/rat/peptide-dbs/rat-peptides.target.txt'\n",
    "#decoyPath = '/disk/raptor/lclhome/mtari008/Proteogenomics/DeepSNAP/data/rat/peptide-dbs/rat-peptides.decoy.txt'\n",
    "targetPath = '/disk/raptor/lclhome/mtari008/Proteomics/crux/crux-output/generate-peptides.target.txt'\n",
    "decoyPath = '/disk/raptor/lclhome/mtari008/Proteomics/crux/crux-output/generate-peptides.decoy.txt'\n",
    "targetspectra_out, targetmasses, targetpeptides = fastaToSpectraBatch(targetPath, spectra_batch_size)\n",
    "decoyspectra_out, decoymasses, decoypeptides = fastaToSpectraBatch(decoyPath, spectra_batch_size)\n",
    "\n",
    "\n",
    "print(len(targetspectra_out), len(targetmasses))\n",
    "print(len(decoyspectra_out), len(decoymasses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1,\n",
      "        0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
      "        0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0,\n",
      "        1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1,\n",
      "        0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1,\n",
      "        0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
      "        1, 0, 0, 1, 1, 0])\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
      "        0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
      "        0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
      "        1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1,\n",
      "        1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n",
      "        1, 1, 0, 1, 1, 1], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "nearest_target_distances, nearest_target_indexes = process.pairwise_distances(\n",
    "    queryspectra_out, targetspectra_out).min(1)\n",
    "\n",
    "nearest_decoy_distances, nearest_decoy_indexes  = process.pairwise_distances(\n",
    "    queryspectra_out,  decoyspectra_out).min(1)\n",
    "\n",
    "nearest_distances, target_decoy = torch.cat((nearest_target_distances.view(1, -1), \n",
    "                                             nearest_decoy_distances.view(1, -1)), dim=0).min(0)\n",
    "\n",
    "print(target_decoy.to('cpu'))\n",
    "\n",
    "sorted_nearest_distances, snd_index = nearest_distances.sort()\n",
    "target_decoy = target_decoy[snd_index]\n",
    "\n",
    "print(target_decoy)\n",
    "\n",
    "## To lookup a peptide corresponding to a value in sorted_nearest_distances at index i:\n",
    "## td = target_deocy[i]            # a binary array. 0: target, 1: decoy\n",
    "## query_index = snd_index[i]        # lookup the index of query spectrum\n",
    "## pep_index = nearest_decoy_indexes[query_index] if td else nearest_target_indexes[query_index]\n",
    "## td_peptide = decoy_peptides[pep_index] if td else target_peptides[pep_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fdr(td, target_fdr):\n",
    "    target_count = 0\n",
    "    decoy_count = 0\n",
    "    q_values = [0] * len(td)\n",
    "    for idx, val in enumerate(td):\n",
    "        if val == 0:\n",
    "            target_count += 1\n",
    "        else:\n",
    "            decoy_count += 1\n",
    "        return_fdr = decoy_count / (idx + 1)\n",
    "        print('{} / {} = {}'.format(decoy_count, idx+1, decoy_count/(idx+1)))\n",
    "        #if return_fdr > target_fdr:\n",
    "        #    return target_count, return_fdr\n",
    "    return target_count, return_fdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 1 = 0.0\n",
      "0 / 2 = 0.0\n",
      "0 / 3 = 0.0\n",
      "0 / 4 = 0.0\n",
      "0 / 5 = 0.0\n",
      "0 / 6 = 0.0\n",
      "0 / 7 = 0.0\n",
      "0 / 8 = 0.0\n",
      "0 / 9 = 0.0\n",
      "0 / 10 = 0.0\n",
      "0 / 11 = 0.0\n",
      "0 / 12 = 0.0\n",
      "0 / 13 = 0.0\n",
      "0 / 14 = 0.0\n",
      "0 / 15 = 0.0\n",
      "0 / 16 = 0.0\n",
      "0 / 17 = 0.0\n",
      "0 / 18 = 0.0\n",
      "0 / 19 = 0.0\n",
      "0 / 20 = 0.0\n",
      "0 / 21 = 0.0\n",
      "0 / 22 = 0.0\n",
      "0 / 23 = 0.0\n",
      "0 / 24 = 0.0\n",
      "0 / 25 = 0.0\n",
      "0 / 26 = 0.0\n",
      "0 / 27 = 0.0\n",
      "0 / 28 = 0.0\n",
      "0 / 29 = 0.0\n",
      "0 / 30 = 0.0\n",
      "0 / 31 = 0.0\n",
      "0 / 32 = 0.0\n",
      "0 / 33 = 0.0\n",
      "0 / 34 = 0.0\n",
      "0 / 35 = 0.0\n",
      "0 / 36 = 0.0\n",
      "0 / 37 = 0.0\n",
      "0 / 38 = 0.0\n",
      "0 / 39 = 0.0\n",
      "0 / 40 = 0.0\n",
      "0 / 41 = 0.0\n",
      "0 / 42 = 0.0\n",
      "0 / 43 = 0.0\n",
      "0 / 44 = 0.0\n",
      "0 / 45 = 0.0\n",
      "1 / 46 = 0.021739130434782608\n",
      "2 / 47 = 0.0425531914893617\n",
      "2 / 48 = 0.041666666666666664\n",
      "2 / 49 = 0.04081632653061224\n",
      "3 / 50 = 0.06\n",
      "3 / 51 = 0.058823529411764705\n",
      "4 / 52 = 0.07692307692307693\n",
      "4 / 53 = 0.07547169811320754\n",
      "4 / 54 = 0.07407407407407407\n",
      "4 / 55 = 0.07272727272727272\n",
      "4 / 56 = 0.07142857142857142\n",
      "4 / 57 = 0.07017543859649122\n",
      "5 / 58 = 0.08620689655172414\n",
      "5 / 59 = 0.0847457627118644\n",
      "5 / 60 = 0.08333333333333333\n",
      "5 / 61 = 0.08196721311475409\n",
      "5 / 62 = 0.08064516129032258\n",
      "5 / 63 = 0.07936507936507936\n",
      "5 / 64 = 0.078125\n",
      "5 / 65 = 0.07692307692307693\n",
      "5 / 66 = 0.07575757575757576\n",
      "5 / 67 = 0.07462686567164178\n",
      "5 / 68 = 0.07352941176470588\n",
      "5 / 69 = 0.07246376811594203\n",
      "5 / 70 = 0.07142857142857142\n",
      "6 / 71 = 0.08450704225352113\n",
      "7 / 72 = 0.09722222222222222\n",
      "7 / 73 = 0.0958904109589041\n",
      "7 / 74 = 0.0945945945945946\n",
      "8 / 75 = 0.10666666666666667\n",
      "9 / 76 = 0.11842105263157894\n",
      "9 / 77 = 0.11688311688311688\n",
      "10 / 78 = 0.1282051282051282\n",
      "11 / 79 = 0.13924050632911392\n",
      "12 / 80 = 0.15\n",
      "12 / 81 = 0.14814814814814814\n",
      "13 / 82 = 0.15853658536585366\n",
      "14 / 83 = 0.1686746987951807\n",
      "15 / 84 = 0.17857142857142858\n",
      "16 / 85 = 0.18823529411764706\n",
      "17 / 86 = 0.19767441860465115\n",
      "18 / 87 = 0.20689655172413793\n",
      "19 / 88 = 0.2159090909090909\n",
      "20 / 89 = 0.2247191011235955\n",
      "20 / 90 = 0.2222222222222222\n",
      "20 / 91 = 0.21978021978021978\n",
      "20 / 92 = 0.21739130434782608\n",
      "20 / 93 = 0.21505376344086022\n",
      "20 / 94 = 0.2127659574468085\n",
      "21 / 95 = 0.22105263157894736\n",
      "21 / 96 = 0.21875\n",
      "22 / 97 = 0.2268041237113402\n",
      "22 / 98 = 0.22448979591836735\n",
      "23 / 99 = 0.23232323232323232\n",
      "23 / 100 = 0.23\n",
      "24 / 101 = 0.2376237623762376\n",
      "25 / 102 = 0.24509803921568626\n",
      "26 / 103 = 0.2524271844660194\n",
      "27 / 104 = 0.25961538461538464\n",
      "28 / 105 = 0.26666666666666666\n",
      "29 / 106 = 0.27358490566037735\n",
      "30 / 107 = 0.2803738317757009\n",
      "30 / 108 = 0.2777777777777778\n",
      "30 / 109 = 0.27522935779816515\n",
      "31 / 110 = 0.2818181818181818\n",
      "32 / 111 = 0.2882882882882883\n",
      "33 / 112 = 0.29464285714285715\n",
      "33 / 113 = 0.2920353982300885\n",
      "33 / 114 = 0.2894736842105263\n",
      "33 / 115 = 0.28695652173913044\n",
      "33 / 116 = 0.28448275862068967\n",
      "33 / 117 = 0.28205128205128205\n",
      "34 / 118 = 0.288135593220339\n",
      "35 / 119 = 0.29411764705882354\n",
      "36 / 120 = 0.3\n",
      "37 / 121 = 0.30578512396694213\n",
      "38 / 122 = 0.3114754098360656\n",
      "39 / 123 = 0.3170731707317073\n",
      "40 / 124 = 0.3225806451612903\n",
      "41 / 125 = 0.328\n",
      "42 / 126 = 0.3333333333333333\n",
      "42 / 127 = 0.33070866141732286\n",
      "43 / 128 = 0.3359375\n",
      "44 / 129 = 0.34108527131782945\n",
      "44 / 130 = 0.3384615384615385\n",
      "44 / 131 = 0.33587786259541985\n",
      "45 / 132 = 0.3409090909090909\n",
      "46 / 133 = 0.3458646616541353\n",
      "46 / 134 = 0.34328358208955223\n",
      "46 / 135 = 0.34074074074074073\n",
      "47 / 136 = 0.34558823529411764\n",
      "47 / 137 = 0.34306569343065696\n",
      "48 / 138 = 0.34782608695652173\n",
      "49 / 139 = 0.35251798561151076\n",
      "50 / 140 = 0.35714285714285715\n",
      "51 / 141 = 0.3617021276595745\n",
      "51 / 142 = 0.3591549295774648\n",
      "51 / 143 = 0.35664335664335667\n",
      "52 / 144 = 0.3611111111111111\n",
      "53 / 145 = 0.36551724137931035\n",
      "54 / 146 = 0.3698630136986301\n",
      "54 / 147 = 0.3673469387755102\n",
      "55 / 148 = 0.3716216216216216\n",
      "56 / 149 = 0.37583892617449666\n",
      "57 / 150 = 0.38\n",
      "(93, 0.38)\n"
     ]
    }
   ],
   "source": [
    "print(fdr(target_decoy, 0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[787.4672, 4338.1767, 2113.0229, 2570.2763, 2698.3713, 686.4195, 4609.6088, 5249.9746, 968.5523, 1096.6473]\n",
      "7103\n"
     ]
    }
   ],
   "source": [
    "print(targetmasses[0:10])\n",
    "print(len(decoypeptides))\n",
    "targetspectra_out, targetmasses, targetpeptides = list(zip(*sorted(zip(targetspectra_out, targetmasses, targetpeptides), \n",
    "                                                                   key=lambda pair: pair[1])))\n",
    "decoyspectra_out, decoymasses, decoypeptides = list(zip(*sorted(zip(decoyspectra_out, decoymasses, decoypeptides),\n",
    "                                                                key=lambda pair: pair[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(targetmasses))\n",
    "print(targetmasses[1000:1010])\n",
    "print(decoymasses[1000:1010])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_range(arr, val, tolerance=3):\n",
    "    assert len(arr) > 0\n",
    "    assert tolerance > 0\n",
    "    assert val > 0\n",
    "    \n",
    "    left = val - tolerance if val - tolerance >= 0 else 0\n",
    "    right = val + tolerance\n",
    "    \n",
    "    ileft = bisect.bisect_left(arr, left)\n",
    "    iright = bisect.bisect_right(arr, right)\n",
    "    \n",
    "    return (ileft, iright-1) if iright - ileft > 0 else (-1, -1)\n",
    "    \n",
    "# Function to insert element \n",
    "def insert(lst, n): \n",
    "    assert not lst or len(lst[0]) == len(n)\n",
    "    \n",
    "    index = num_psm\n",
    "    # Searching for the position \n",
    "    for i in range(len(lst)): \n",
    "        if lst[i][0] > n[0]: \n",
    "            index = i \n",
    "            break\n",
    "      \n",
    "    # Inserting n in the list \n",
    "    lst = lst[:index] + [n] + lst[index:] \n",
    "    return lst[:num_psm]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_L2_Dist(queryspectra, querymasses, dbspectra, dbmasses, pre_tol=3, keep_psm=1):\n",
    "    prev = 0\n",
    "    psm_scores = []\n",
    "    psm_pepids = []\n",
    "    \n",
    "    for ind, (spec, spec_mass) in enumerate(zip(queryspectra, querymasses)):\n",
    "        left, right = find_range(dbmasses, spec_mass, pre_tol)\n",
    "        if left != -1 and right != -1:\n",
    "            candidate_specs = dbspectra[left:right+1]\n",
    "            l_scores = np.linalg.norm(np.subtract(candidate_specs, spec), axis=1)**2\n",
    "            psm_pepids.append(left + l_scores.argsort()[:keep_psm]) #add argsort later\n",
    "            psm_scores.append(np.sort(l_scores)[:keep_psm])\n",
    "            #print(ind)\n",
    "            new = int((ind/len(queryspectra)) * 100)\n",
    "            if new > prev:\n",
    "                clear_output(wait=True)\n",
    "                print(str(new) + '%')\n",
    "                prev = new\n",
    "        else:\n",
    "            print('***********error**************')\n",
    "            print('ind: ' + str(ind))\n",
    "            print('spec_mass: ' + str(spec_mass))\n",
    "            print('**********end error************')\n",
    "            \n",
    "    return psm_scores, psm_pepids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_xcorr(queryspectra, querymasses, dbspectra, dbmasses, pre_tol=3, keep_psm=1):\n",
    "    prev = 0\n",
    "    psm_scores = []\n",
    "    psm_pepids = []\n",
    "    \n",
    "    for ind, (spec, spec_mass) in enumerate(zip(queryspectra, querymasses)):\n",
    "        left, right = find_range(dbmasses, spec_mass, pre_tol)\n",
    "        if left != -1 and right != -1:\n",
    "            candidate_specs = dbspectra[left:right+1]\n",
    "            l_scores = np.dot(candidate_specs, spec)\n",
    "            psm_pepids.append(left + l_scores.argsort()[::-1][:keep_psm]) #add argsort later\n",
    "            psm_scores.append(np.sort(l_scores)[::-1][:keep_psm])\n",
    "            #print(ind)\n",
    "            new = int((ind/len(queryspectra)) * 100)\n",
    "            if new > prev:\n",
    "                clear_output(wait=True)\n",
    "                print(str(new) + '%')\n",
    "                prev = new\n",
    "        else:\n",
    "            print('***********error**************')\n",
    "            print('ind: ' + str(ind))\n",
    "            print('spec_mass: ' + str(spec_mass))\n",
    "            print('**********end error************')\n",
    "            \n",
    "    return psm_scores, psm_pepids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# targetpsm_scores, targetpsm_ids = calculate_L2_Dist(queryspectra_out, spectramasses, targetspectra_out,\n",
    "#                                      targetmasses, precursor_tolerance, num_psm)\n",
    "# decoypsm_scores, decoypsm_ids = calculate_L2_Dist(queryspectra_out, spectramasses, decoyspectra_out,\n",
    "#                                      decoymasses, precursor_tolerance, num_psm)\n",
    "targetpsm_scores, targetpsm_ids = calculate_xcorr(queryspectra_out, spectramasses, targetspectra_out,\n",
    "                                     targetmasses, precursor_tolerance, num_psm)\n",
    "decoypsm_scores, decoypsm_ids = calculate_xcorr(queryspectra_out, spectramasses, decoyspectra_out,\n",
    "                                     decoymasses, precursor_tolerance, num_psm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(targetmasses[2000000:2000010])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(targetspectra_out))\n",
    "print(len(decoyspectra_out))\n",
    "\n",
    "print(len(targetpsm_scores))\n",
    "print(len(decoypsm_scores))\n",
    "\n",
    "print(targetpsm_scores[0:10])\n",
    "print(decoypsm_scores[0:10])\n",
    "\n",
    "targetpsm_scores = np.asarray(targetpsm_scores).flatten()\n",
    "decoypsm_scores = np.asarray(decoypsm_scores).flatten()\n",
    "\n",
    "targetpsm_ids = np.asarray(targetpsm_ids).flatten()\n",
    "decoypsm_ids = np.asarray(decoypsm_ids).flatten()\n",
    "\n",
    "targetpsm_peps = np.asarray(targetpeptides)[targetpsm_ids]\n",
    "decoypsm_peps = np.asarray(decoypeptides)[decoypsm_ids]\n",
    "\n",
    "#targetpsm_ids = targetpsm_ids[np.argsort(np.asarray(targetpsm_scores).flatten())]\n",
    "#decoypsm_ids = decoypsm_ids[np.argsort(np.asarray(decoypsm_scores).flatten())]\n",
    "\n",
    "sorted_targets = np.sort(np.asarray(targetpsm_scores).flatten())[::-1]\n",
    "sorted_decoys = np.sort(np.asarray(decoypsm_scores).flatten())[::-1]\n",
    "\n",
    "print(targetpsm_ids[0:10])\n",
    "print(decoypsm_ids[0:10])\n",
    "\n",
    "print(sorted_targets[0:100])\n",
    "print(sorted_decoys[0:100])\n",
    "\n",
    "#targetpsm_scores = np.column_stack((targetpsm_scores, np.ones(len(targetpsm_scores))))\n",
    "#decoypsm_scores = np.column_stack((decoypsm_scores, np.zeros(len(decoypsm_scores))))\n",
    "#decoypsm_scores = np.asarray(decoypsm_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targetpsm_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    data={'spectrum_ids':np.arange(len(targetpsm_peps)), 'target_psms':targetpsm_peps, \n",
    "          'targetpsm_scores':targetpsm_scores, 'decoy_psms':decoypsm_peps, 'decoypsm_scores':decoypsm_scores})\n",
    "df.to_csv('deepsearch.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortedpeps = np.array(sortedpeps)\n",
    "correct_matches = 0\n",
    "for ind, psms in enumerate(psm_scores):\n",
    "    #print('ind: ' + str(ind) + ', mass: ' + str(sortedspecmasses[ind]))\n",
    "    #print('psms: ' + str(psms) + ', psm mass: ' + str(sortedpepmasses[psms[0]]))\n",
    "    cand_peps = sortedpeps[psms]\n",
    "    #print(cand_peps)\n",
    "    for pep in cand_peps:\n",
    "        #print('pepidmass: ' + str(pepidmass[pep][0]))\n",
    "        #print('ids: ' + str(ids[ind]) + ', in: ' + str(pepidmass[pep][0]))\n",
    "        if ids[ind] in pepidmass[pep][0]:\n",
    "            correct_matches += 1\n",
    "            break\n",
    "print(len(psm_scores))\n",
    "print(correct_matches)\n",
    "print(str((correct_matches/len(psm_scores)) * 100) + '% correct matches in top ' + str(num_psm) + ' psms.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch Work:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(5184 - 1739)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('/disk/raptor/lclhome/mtari008/Proteogenomics/DeepSNAP/data/rat/peptide-dbs/rat-peptides.target.txt')\n",
    "tlines = file.readlines()\n",
    "print(len(tlines))\n",
    "tpeps = list((tline.split('\\t')[0], float(tline.split('\\t')[1])) for tline in tlines)\n",
    "tpeps = sorted(tpeps, key=lambda pair: pair[1])\n",
    "print(tpeps[10000:10010])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open('/disk/raptor/lclhome/mtari008/Proteogenomics/DeepSNAP/data/rat/peptide-dbs/rat-peptides.decoy.txt')\n",
    "tlines = file.readlines()\n",
    "print(len(tlines))\n",
    "tpeps = list((tline.split('\\t')[0], float(tline.split('\\t')[1])) for tline in tlines)\n",
    "tpeps = sorted(tpeps, key=lambda pair: pair[1])\n",
    "print(tpeps[10000:10010])\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[5., 5., 5.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [5., 5., 5.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 3)\n",
    "z = (torch.ones(3) * 5).view(1, 3)\n",
    "print(x)\n",
    "print(z)\n",
    "# or this\n",
    "#z = torch.ones(2, 3, 1) * 5\n",
    "y = torch.cat((x, z), dim=0)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5., 3., 4., 1., 2.]])\n",
      "tensor([[1., 3., 2., 5., 4.]])\n",
      "tensor([[5., 3., 4., 1., 2.],\n",
      "        [1., 3., 2., 5., 4.]])\n",
      "tensor([[1., 2., 3., 4., 5.],\n",
      "        [5., 4., 3., 2., 1.]])\n"
     ]
    }
   ],
   "source": [
    "## Keep this cell....\n",
    "## How to sort a 2D tensor by its first row.....\n",
    "x = torch.Tensor([5., 3., 4., 1., 2.]).view(1, -1)\n",
    "z = torch.Tensor([1., 3., 2., 5., 4.]).view(1, -1)\n",
    "print(x)\n",
    "print(z)\n",
    "# or this\n",
    "#z = torch.ones(2, 3, 1) * 5\n",
    "y = torch.cat((x, z), dim=0)\n",
    "_, sorted_index_y = y[0, :].sort()\n",
    "sorted_y = y[:, sorted_index_y]\n",
    "print(y)\n",
    "print(sorted_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
