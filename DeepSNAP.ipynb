{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "import numpy as np\n",
    "import random as rand\n",
    "import queue\n",
    "import csv\n",
    "from collections import OrderedDict\n",
    "from IPython.display import clear_output\n",
    "import csv\n",
    "from heapq import merge\n",
    "from sklearn import preprocessing\n",
    "import gc\n",
    "import os\n",
    "\n",
    "from sklearn.datasets import make_circles, make_moons\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from IPython.core.debugger import set_trace\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "rand.seed(37)\n",
    "AAMass = {'A':71.037114, 'C':103.009185, 'D':115.026943, 'E':129.042593, 'F':147.068414, 'G':57.021464, 'H':137.058912,\n",
    "          'I':113.084064, 'K':128.094963, 'L':113.084064, 'M':131.040485, 'N':114.042927, 'P':97.052764, 'Q':128.058578,\n",
    "          'R':156.101111, 'S':87.032028, 'T':101.047679, 'V':99.068414, 'W':186.079313, 'Y':163.0633}\n",
    "\n",
    "H2O = 18.015\n",
    "NH3 = 17.031\n",
    "PROTON = 1.00727647\n",
    "specsize = 8000\n",
    "charge = 2\n",
    "use_mods = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "printing by:\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "(8000,)\n",
      "113.084064\n"
     ]
    }
   ],
   "source": [
    "def GetAAMass(AA):\n",
    "    return AAMass[AA] + 57.021464 if AA == 'C' else AAMass[AA]\n",
    "\n",
    "def GetSpectrum(Seq):\n",
    "    size = len(Seq)\n",
    "    outsize = 2*size\n",
    "    bspectrum = []\n",
    "    bspectrumaux = []\n",
    "    yspectrum = []\n",
    "    yspectrumaux = []\n",
    "    \n",
    "    bspectrum.append(GetAAMass(Seq[0]) + PROTON)\n",
    "    yspectrum.append(GetAAMass(Seq[-1]) + H2O + PROTON)\n",
    "    \n",
    "    for i, (fAA, bAA) in enumerate(zip((Seq[1:]), Seq[-2::-1])):\n",
    "        bspectrum.append(bspectrum[i] + GetAAMass(fAA))\n",
    "        yspectrum.append(yspectrum[i] + GetAAMass(bAA))\n",
    "    \n",
    "#    bspectrumaux = [(bion + PROTON) / 2 for bion in bspectrum]\n",
    "#    bspectrumaux.extend([bion - H2O for bion in bspectrum])\n",
    "#    bspectrumaux.extend([bion - NH3 for bion in bspectrum])\n",
    "    \n",
    "#    yspectrumaux = [(yion + PROTON) / 2 for yion in yspectrum]\n",
    "#    yspectrumaux.extend([yion - H2O for yion in yspectrum])\n",
    "#    yspectrumaux.extend([yion - NH3 for yion in yspectrum])\n",
    "    \n",
    "#    bspectrum.extend(bspectrumaux)\n",
    "#    yspectrum.extend(yspectrumaux)\n",
    "    \n",
    "#     bspectrum.sort()\n",
    "#     yspectrum.sort()\n",
    "    \n",
    "    mergedout = list(merge(bspectrum, yspectrum))\n",
    "    if mergedout[-1] > specsize:\n",
    "        print(mergedout[-1])\n",
    "        print(Seq)\n",
    "    tspec = np.zeros(specsize)\n",
    "    tspec[np.rint(mergedout).astype(int)] = 1\n",
    "    return tspec\n",
    "\n",
    "by = GetSpectrum('ACDEFG')\n",
    "print('printing by:\\n' + str(by))\n",
    "print(by.shape)\n",
    "print(AAMass['L'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_signals():\n",
    "    isName = isMW = isNumPeaks = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99%\n",
      "<class 'list'>\n",
      "len of file: 50017570\n",
      "130172\n"
     ]
    }
   ],
   "source": [
    "f = open(\"data/human_consensus_final_true_lib.msp\", \"r\")\n",
    "lines = f.readlines()\n",
    "newcontents = []\n",
    "specid = 0\n",
    "prev = 0\n",
    "num_specs = 0\n",
    "for i, line in enumerate(lines):\n",
    "    if line.startswith('Name') and '_' in line:\n",
    "        l_charge = int(line[line.find('_') - 1])\n",
    "        if l_charge != charge:\n",
    "            continue\n",
    "        if use_mods:\n",
    "            num_specs += 1\n",
    "        elif '(' not in line and ')' not in line:\n",
    "            num_specs += 1\n",
    "        new = int((i/len(lines)) * 100)\n",
    "        if (new > prev):\n",
    "            clear_output(wait=True)\n",
    "            print(str(new) + '%')\n",
    "            prev = new\n",
    "f.close()\n",
    "print(type(lines))\n",
    "print('len of file: ' + str(len(lines)))\n",
    "print(num_specs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sin Mods:\n",
    "Number of charge 1 examples: 18230  \n",
    "Number of charge 2 examples: 130172  \n",
    "Number of charge 3 examples: 70741  \n",
    "  \n",
    "#### Con Mods:\n",
    "Number of charge 2 examples: 184994"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getrandmod(seq, nummods=1):\n",
    "    AAs = list(AAMass.keys())\n",
    "    res = temp = seq\n",
    "    for i in range(nummods):\n",
    "        while res == temp:\n",
    "            randindx = rand.randint(0, len(seq)-1)\n",
    "            randmod = AAs[rand.randint(0, len(AAs))-1]\n",
    "            temp = temp[:randindx] + randmod + temp[randindx+1:]\n",
    "        res = temp\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWINSTWDG\n"
     ]
    }
   ],
   "source": [
    "seq = 'AFINSTWDG'\n",
    "print(getrandmod(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readmspwithdecoy(mspfile):\n",
    "    f=open(mspfile, \"r\")\n",
    "    lines = f.readlines()\n",
    "    f.close()\n",
    "    #fo = open('output.csv', 'w')\n",
    "    #fo.write('Q,P,N\\n')\n",
    "    fixedlen = 300\n",
    "    dataset = []\n",
    "    label = []\n",
    "    print('len of file: ' + str(len(lines)))\n",
    "    count = 0\n",
    "    limit = 200000\n",
    "    pep = mass = numPeaks = 0\n",
    "    #spec = []\n",
    "    isName = isMW = isNumPeaks = False\n",
    "    new = prev = 0\n",
    "    maxpeaks = maxmoz = 0\n",
    "    i = 0\n",
    "    while i < len(lines) and limit > 0:\n",
    "        line = lines[i]\n",
    "        i += 1\n",
    "        splits = line.split(':') \n",
    "        if (splits[0] == 'Name') and '_' in line:\n",
    "            split1 = splits[1]\n",
    "            l_charge = int(split1[split1.find('_') - 1])\n",
    "            if l_charge != charge: # l_charge == l_charge always true.\n",
    "                continue\n",
    "            if use_mods:\n",
    "                pep = split1.split('/')[0].lstrip(' ')\n",
    "                isName = True\n",
    "            elif '(' not in splits[1] and ')' not in splits[1]:\n",
    "                pep = split1.split('/')[0].lstrip(' ')\n",
    "                isName = True\n",
    "\n",
    "        if (isName and splits[0] == 'MW'):\n",
    "            mass = float(splits[1])\n",
    "            if round(mass) < specsize:\n",
    "                isMW = True\n",
    "                #limit = limit - 1\n",
    "            else:\n",
    "                isName = isMW = isNumPeaks = False\n",
    "                continue\n",
    "\n",
    "        if (isName and isMW and splits[0] == 'Num peaks'):\n",
    "            numPeaks = int(splits[1])\n",
    "            if numPeaks > maxpeaks:\n",
    "                maxpeaks = numPeaks\n",
    "\n",
    "            spec = np.zeros(specsize)\n",
    "            while (lines[i] != '\\n'):\n",
    "                mzline = lines[i]\n",
    "                i +=1\n",
    "                mzsplits = mzline.split('\\t')\n",
    "                moz, intensity = float(mzsplits[0]), float(mzsplits[1])\n",
    "                if moz > maxmoz:\n",
    "                    maxmoz = moz\n",
    "                spec[round(moz)] += round(intensity)\n",
    "\n",
    "            spec = np.clip(spec, None, 1000.0)\n",
    "            spec = preprocessing.scale(spec)\n",
    "\n",
    "            isNumPeaks = True\n",
    "\n",
    "        if isName and isMW and isNumPeaks:\n",
    "            isName = isMW = isNumPeaks = False\n",
    "            #revPep = pep[0] + pep[1:-1][::-1] + pep[-1]\n",
    "            revPep = getrandmod(pep)\n",
    "            if pep == revPep:\n",
    "                print('decoy is the same. shuffling')\n",
    "                #revPep = ''.join(rand.sample(revPep,len(revPep)))\n",
    "                revPep = getrandmod(pep, len(pep))\n",
    "                print(pep)\n",
    "                print(revPep)\n",
    "            tspec = preprocessing.scale(GetSpectrum(pep))\n",
    "            rtspec = preprocessing.scale(GetSpectrum(revPep))\n",
    "\n",
    "            dataset.append([spec, tspec, rtspec])\n",
    "            label.append([1, -1])\n",
    "\n",
    "            count = count + 1\n",
    "            pep = mass = numPeaks = 0\n",
    "            spec = []\n",
    "            new = int((i/len(lines)) * 100)\n",
    "            if (new > prev):\n",
    "                #clear_output(wait=True)\n",
    "                print(str(new) + '%')\n",
    "                prev = new\n",
    "    \n",
    "    print('max peaks: ' + str(maxpeaks))\n",
    "    print('count: ' + str(count))\n",
    "    print('max moz: ' + str(maxmoz))\n",
    "    return dataset, label\n",
    "# print('max peaks: ' + str(maxpeaks))\n",
    "# print('count: ' + str(count))\n",
    "# print('max moz: ' + str(maxmoz))\n",
    "# #fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len of file: 50017570\n",
      "1%\n",
      "2%\n",
      "3%\n",
      "4%\n",
      "5%\n",
      "6%\n",
      "7%\n",
      "8%\n",
      "9%\n",
      "10%\n",
      "11%\n",
      "12%\n",
      "13%\n",
      "14%\n",
      "15%\n",
      "16%\n",
      "17%\n",
      "18%\n",
      "19%\n",
      "20%\n",
      "21%\n",
      "22%\n",
      "23%\n",
      "24%\n",
      "25%\n",
      "26%\n",
      "27%\n",
      "28%\n",
      "29%\n",
      "30%\n",
      "31%\n",
      "32%\n",
      "33%\n",
      "34%\n",
      "35%\n",
      "36%\n",
      "37%\n",
      "38%\n",
      "39%\n",
      "40%\n",
      "41%\n",
      "42%\n",
      "43%\n",
      "44%\n",
      "45%\n",
      "46%\n",
      "47%\n",
      "48%\n",
      "49%\n",
      "50%\n",
      "51%\n",
      "52%\n",
      "53%\n",
      "54%\n",
      "55%\n",
      "56%\n",
      "57%\n",
      "58%\n",
      "59%\n",
      "60%\n",
      "61%\n",
      "62%\n",
      "63%\n",
      "64%\n",
      "65%\n",
      "66%\n",
      "67%\n",
      "68%\n",
      "69%\n",
      "70%\n",
      "71%\n",
      "72%\n",
      "73%\n",
      "74%\n",
      "75%\n",
      "76%\n",
      "77%\n",
      "78%\n",
      "79%\n",
      "80%\n",
      "81%\n",
      "82%\n",
      "83%\n",
      "84%\n",
      "85%\n",
      "86%\n",
      "87%\n",
      "88%\n",
      "89%\n",
      "90%\n",
      "91%\n",
      "92%\n",
      "93%\n",
      "94%\n",
      "95%\n",
      "96%\n",
      "97%\n",
      "98%\n",
      "99%\n",
      "max peaks: 251\n",
      "count: 130172\n",
      "max moz: 2616.7\n"
     ]
    }
   ],
   "source": [
    "dataset, label = readmspwithdecoy(\"data/human_consensus_final_true_lib.msp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitting...\n",
      "converting to tensors...\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "print('splitting...')\n",
    "tmpTrainData, tmpTestData = train_test_split(\n",
    "            dataset, test_size = 0.2, random_state = rand.randint(0, 1000), shuffle = True)\n",
    "\n",
    "print('converting to tensors...')\n",
    "XTrainTensor = torch.tensor(tmpTrainData, dtype=torch.float)\n",
    "XTestTensor = torch.tensor(tmpTestData, dtype=torch.float)\n",
    "print('done')\n",
    "del dataset, tmpTrainData, tmpTestData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tmpTrainData, tmpTestData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=XTrainTensor, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=XTestTensor, batch_size=batch_size, shuffle=False)\n",
    "del XTrainTensor, XTestTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_learn = True\n",
    "save_frequency = 2\n",
    "lr = 0.00001\n",
    "num_epochs = 200\n",
    "weight_decay = 0.0001\n",
    "margin = 0.2\n",
    "#torch.manual_seed(0)\n",
    "#torch.cuda.manual_seed(0)\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loader = torch.load('train_loader.pt')\n",
    "#test_loader = torch.load('test_loader.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.searching = False\n",
    "        \n",
    "        self.linear1_1 = nn.Linear(specsize, 1024)\n",
    "        self.linear1_2 = nn.Linear(1024, 512)\n",
    "        #self.linear1_3 = nn.Linear(512, 256)\n",
    "        \n",
    "        self.linear2_1 = nn.Linear(specsize, 1024)\n",
    "        self.linear2_2 = nn.Linear(1024, 512)\n",
    "        #self.linear2_3 = nn.Linear(512, 256)\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        #self.dropout3 = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        res = []\n",
    "        x = data[:, 0]\n",
    "        x = self.linear1_1(x.view(-1, specsize))\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.linear1_2(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        #x = self.dropout2(x)\n",
    "        #x = self.linear1_3(x)\n",
    "        #x = F.relu(x)\n",
    "        #if not self.searching:\n",
    "        #    x = F.normalize(x)\n",
    "        res.append(x)\n",
    "        for i in range(data.shape[1]-1):\n",
    "            x = data[:, i+1]\n",
    "            x = self.linear2_1(x.view(-1, specsize))\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout1(x)\n",
    "            x = self.linear2_2(x)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout2(x)\n",
    "            #x = self.dropout2(x)\n",
    "            #x = self.linear2_3(x)\n",
    "            #x = F.relu(x)\n",
    "            #if not self.searching:\n",
    "            #x = F.normalize(x)\n",
    "            #x = self.linear1_3(x)\n",
    "            #x = F.relu(x)\n",
    "            res.append(x)\n",
    "        \n",
    "        return res\n",
    "    \n",
    "    def name(self):\n",
    "        return \"Net\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1024, 2, 8000])\n"
     ]
    }
   ],
   "source": [
    "for (tid, data) in enumerate(train_loader):\n",
    "    if tid == 0:\n",
    "        print(data[:,0:3:2].shape)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hinge = torch.nn.HingeEmbeddingLoss()\n",
    "triplet_loss = nn.TripletMarginLoss(margin=margin, p=2, reduction='sum')\n",
    "\n",
    "def train(model, device, train_loader, epoch, optimizer):\n",
    "    model.train()\n",
    "    \n",
    "    accurate_labels = 0\n",
    "    all_labels = 0\n",
    "    for (batch_idx, data) in enumerate(train_loader):\n",
    "        \n",
    "        data = data.to(device)    \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        Q, P, N = model(data)\n",
    "        \n",
    "        loss = triplet_loss(Q, P, N)\n",
    "        \n",
    "        loss.backward()\n",
    "            \n",
    "        optimizer.step()\n",
    "        \n",
    "        accurate_labels = accurate_labels + 2*torch.sum(F.pairwise_distance(Q, P)**2 - \n",
    "                                                        F.pairwise_distance(Q, N)**2 + margin < 0)\n",
    "        \n",
    "        all_labels = all_labels + 2*len(Q)  \n",
    "    \n",
    "    accuracy = 100. * float(accurate_labels) / all_labels\n",
    "    train_accuracy.append(accuracy)\n",
    "    train_loss.append(loss/batch_size)\n",
    "    print('Epoch: ' + str(epoch))\n",
    "    print('Train accuracy: {}/{} ({:.3f}%)\\tLoss: {:.6f}'.format(accurate_labels, all_labels, accuracy, loss))\n",
    "    \n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        accurate_labels = 0\n",
    "        all_labels = 0\n",
    "        loss = 0\n",
    "        \n",
    "        for (batch_idx, data) in enumerate(test_loader):\n",
    "            \n",
    "            data = data.to(device)    \n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            Q, P, N = model(data)\n",
    "            \n",
    "            loss = triplet_loss(Q, P, N)\n",
    "            \n",
    "            accurate_labels = accurate_labels + 2*torch.sum(F.pairwise_distance(Q, P)**2 - \n",
    "                                                        F.pairwise_distance(Q, N)**2 + margin < 0)\n",
    "            \n",
    "            all_labels = all_labels + 2*len(Q)\n",
    "                \n",
    "        accuracy = 100. * float(accurate_labels) / all_labels\n",
    "        test_accuracy.append(accuracy)\n",
    "        test_loss.append(loss/batch_size)\n",
    "        print('Test accuracy: {}/{} ({:.3f}%)\\tLoss: {:.6f}'.format(accurate_labels, all_labels, accuracy, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneshot(model, device, data):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(len(data)):\n",
    "            data[i] = data[i].to(device)\n",
    "            \n",
    "        output = model(data)\n",
    "        return torch.squeeze(torch.argmax(output, dim=1)).cpu().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Train accuracy: 146106/208274 (70.151%)\tLoss: 91.559074\n",
      "Test accuracy: 44192/52070 (84.870%)\tLoss: 28.814447\n",
      "Epoch: 1\n",
      "Train accuracy: 145664/208274 (69.939%)\tLoss: 93.563744\n",
      "Test accuracy: 43314/52070 (83.184%)\tLoss: 30.347076\n",
      "Epoch: 2\n",
      "Train accuracy: 144826/208274 (69.536%)\tLoss: 97.943008\n",
      "Test accuracy: 41974/52070 (80.611%)\tLoss: 32.558372\n",
      "Epoch: 3\n",
      "Train accuracy: 143316/208274 (68.811%)\tLoss: 93.328125\n",
      "Test accuracy: 40336/52070 (77.465%)\tLoss: 34.893486\n",
      "Epoch: 4\n",
      "Train accuracy: 141330/208274 (67.858%)\tLoss: 85.903488\n",
      "Test accuracy: 37994/52070 (72.967%)\tLoss: 37.723900\n",
      "Epoch: 5\n",
      "Train accuracy: 140060/208274 (67.248%)\tLoss: 97.854370\n",
      "Test accuracy: 35352/52070 (67.893%)\tLoss: 40.553528\n",
      "Epoch: 6\n",
      "Train accuracy: 138700/208274 (66.595%)\tLoss: 89.202606\n",
      "Test accuracy: 32178/52070 (61.798%)\tLoss: 43.620953\n",
      "Epoch: 7\n",
      "Train accuracy: 137170/208274 (65.860%)\tLoss: 89.111954\n",
      "Test accuracy: 28792/52070 (55.295%)\tLoss: 47.016983\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-956bcaa2e7b3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-8a5a4b644acd>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, epoch, optimizer)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0maccurate_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mall_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_shared\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__module__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'numpy'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'str_'\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mand\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'string_'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "test_loss = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "#model = Net().to(device)\n",
    "model.linear1_1.weight.requires_grad = False\n",
    "model.linear1_1.bias.requires_grad = False\n",
    "model.linear1_2.weight.requires_grad = False\n",
    "model.linear1_2.bias.requires_grad = False\n",
    "   \n",
    "if do_learn: # training mode\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    #optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train(model, device, train_loader, epoch, optimizer)\n",
    "        test(model, device, test_loader)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'models/siamese99.7%.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove modifications  \n",
    "use one charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
