{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import ExcelWriter\n",
    "from pandas import ExcelFile\n",
    "import numpy as np\n",
    "import random as rand\n",
    "import queue\n",
    "import csv\n",
    "from collections import OrderedDict\n",
    "from IPython.display import clear_output\n",
    "import csv\n",
    "from heapq import merge\n",
    "from sklearn import preprocessing\n",
    "import gc\n",
    "import os\n",
    "\n",
    "from sklearn.datasets import make_circles, make_moons\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from IPython.core.debugger import set_trace\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "\n",
    "rand.seed(37)\n",
    "\n",
    "from src.snapconfig import config\n",
    "from src.snapprocess import simulatespectra as sim\n",
    "from src.snaputils import reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# AAMass = {'A':71.037114, 'C':103.009185, 'D':115.026943, 'E':129.042593, 'F':147.068414, 'G':57.021464, 'H':137.058912,\n",
    "#           'I':113.084064, 'K':128.094963, 'L':113.084064, 'M':131.040485, 'N':114.042927, 'P':97.052764, 'Q':128.058578,\n",
    "#           'R':156.101111, 'S':87.032028, 'T':101.047679, 'V':99.068414, 'W':186.079313, 'Y':163.0633}\n",
    "\n",
    "# H2O = 18.015\n",
    "# NH3 = 17.031\n",
    "# PROTON = 1.00727647\n",
    "# specsize = 8000\n",
    "# charge = 2\n",
    "# use_mods = False\n",
    "\n",
    "# def GetAAMass(AA):\n",
    "#     return AAMass[AA] + 57.021464 if AA == 'C' else AAMass[AA]\n",
    "\n",
    "# def GetSpectrum(Seq):\n",
    "#     size = len(Seq)\n",
    "#     outsize = 2*size\n",
    "#     bspectrum = []\n",
    "#     bspectrumaux = []\n",
    "#     yspectrum = []\n",
    "#     yspectrumaux = []\n",
    "    \n",
    "#     bspectrum.append(GetAAMass(Seq[0]) + PROTON)\n",
    "#     yspectrum.append(GetAAMass(Seq[-1]) + H2O + PROTON)\n",
    "    \n",
    "#     for i, (fAA, bAA) in enumerate(zip((Seq[1:]), Seq[-2::-1])):\n",
    "#         bspectrum.append(bspectrum[i] + GetAAMass(fAA))\n",
    "#         yspectrum.append(yspectrum[i] + GetAAMass(bAA))\n",
    "    \n",
    "# #    bspectrumaux = [(bion + PROTON) / 2 for bion in bspectrum]\n",
    "# #    bspectrumaux.extend([bion - H2O for bion in bspectrum])\n",
    "# #    bspectrumaux.extend([bion - NH3 for bion in bspectrum])\n",
    "    \n",
    "# #    yspectrumaux = [(yion + PROTON) / 2 for yion in yspectrum]\n",
    "# #    yspectrumaux.extend([yion - H2O for yion in yspectrum])\n",
    "# #    yspectrumaux.extend([yion - NH3 for yion in yspectrum])\n",
    "    \n",
    "# #    bspectrum.extend(bspectrumaux)\n",
    "# #    yspectrum.extend(yspectrumaux)\n",
    "    \n",
    "# #     bspectrum.sort()\n",
    "# #     yspectrum.sort()\n",
    "    \n",
    "#     mergedout = list(merge(bspectrum, yspectrum))\n",
    "#     if mergedout[-1] > specsize:\n",
    "#         print(mergedout[-1])\n",
    "#         print(Seq)\n",
    "#     tspec = np.zeros(specsize)\n",
    "#     tspec[np.rint(mergedout).astype(int)] = 1\n",
    "#     return tspec\n",
    "\n",
    "# by = GetSpectrum('ACDEFG')\n",
    "# print('printing by:\\n' + str(by))\n",
    "# print(by.shape)\n",
    "# print(AAMass['L'])\n",
    "\n",
    "#### Sin Mods:\n",
    "# Number of charge 1 examples: 18230  \n",
    "# Number of charge 2 examples: 130172  \n",
    "# Number of charge 3 examples: 70741  \n",
    "  \n",
    "#### Con Mods:\n",
    "# Number of charge 2 examples: 184994\n",
    "\n",
    "# def getrandmod(seq, nummods=1):\n",
    "#     AAs = list(AAMass.keys())\n",
    "#     res = temp = seq\n",
    "#     for i in range(nummods):\n",
    "#         while res == temp:\n",
    "#             randindx = rand.randint(0, len(seq)-1)\n",
    "#             randmod = AAs[rand.randint(0, len(AAs))-1]\n",
    "#             temp = temp[:randindx] + randmod + temp[randindx+1:]\n",
    "#         res = temp\n",
    "#     return res\n",
    "\n",
    "# seq = 'AFINSTWDG'\n",
    "# print(getrandmod(seq))\n",
    "\n",
    "# def readmspwithdecoy(mspfile):\n",
    "#     f=open(mspfile, \"r\")\n",
    "#     lines = f.readlines()\n",
    "#     f.close()\n",
    "#     #fo = open('output.csv', 'w')\n",
    "#     #fo.write('Q,P,N\\n')\n",
    "#     fixedlen = 300\n",
    "#     dataset = []\n",
    "#     label = []\n",
    "#     print('len of file: ' + str(len(lines)))\n",
    "#     count = 0\n",
    "#     limit = 200000\n",
    "#     pep = mass = numPeaks = 0\n",
    "#     #spec = []\n",
    "#     isName = isMW = isNumPeaks = False\n",
    "#     new = prev = 0\n",
    "#     maxpeaks = maxmoz = 0\n",
    "#     i = 0\n",
    "#     while i < len(lines) and limit > 0:\n",
    "#         line = lines[i]\n",
    "#         i += 1\n",
    "#         splits = line.split(':') \n",
    "#         if (splits[0] == 'Name') and '_' in line:\n",
    "#             split1 = splits[1]\n",
    "#             l_charge = int(split1[split1.find('_') - 1])\n",
    "#             if l_charge != charge: # l_charge == l_charge always true.\n",
    "#                 continue\n",
    "#             if use_mods:\n",
    "#                 pep = split1.split('/')[0].lstrip(' ')\n",
    "#                 isName = True\n",
    "#             elif '(' not in splits[1] and ')' not in splits[1]:\n",
    "#                 pep = split1.split('/')[0].lstrip(' ')\n",
    "#                 isName = True\n",
    "\n",
    "#         if (isName and splits[0] == 'MW'):\n",
    "#             mass = float(splits[1])\n",
    "#             if round(mass) < specsize:\n",
    "#                 isMW = True\n",
    "#                 #limit = limit - 1\n",
    "#             else:\n",
    "#                 isName = isMW = isNumPeaks = False\n",
    "#                 continue\n",
    "\n",
    "#         if (isName and isMW and splits[0] == 'Num peaks'):\n",
    "#             numPeaks = int(splits[1])\n",
    "#             if numPeaks > maxpeaks:\n",
    "#                 maxpeaks = numPeaks\n",
    "\n",
    "#             spec = np.zeros(specsize)\n",
    "#             while (lines[i] != '\\n'):\n",
    "#                 mzline = lines[i]\n",
    "#                 i +=1\n",
    "#                 mzsplits = mzline.split('\\t')\n",
    "#                 moz, intensity = float(mzsplits[0]), float(mzsplits[1])\n",
    "#                 if moz > maxmoz:\n",
    "#                     maxmoz = moz\n",
    "#                 spec[round(moz)] += round(intensity)\n",
    "\n",
    "#             spec = np.clip(spec, None, 1000.0)\n",
    "#             spec = preprocessing.scale(spec)\n",
    "\n",
    "#             isNumPeaks = True\n",
    "\n",
    "#         if isName and isMW and isNumPeaks:\n",
    "#             isName = isMW = isNumPeaks = False\n",
    "#             #revPep = pep[0] + pep[1:-1][::-1] + pep[-1]\n",
    "#             revPep = getrandmod(pep)\n",
    "#             if pep == revPep:\n",
    "#                 print('decoy is the same. shuffling')\n",
    "#                 #revPep = ''.join(rand.sample(revPep,len(revPep)))\n",
    "#                 revPep = getrandmod(pep, len(pep))\n",
    "#                 print(pep)\n",
    "#                 print(revPep)\n",
    "#             tspec = preprocessing.scale(GetSpectrum(pep))\n",
    "#             rtspec = preprocessing.scale(GetSpectrum(revPep))\n",
    "\n",
    "#             dataset.append([spec, tspec, rtspec])\n",
    "#             label.append([1, -1])\n",
    "\n",
    "#             count = count + 1\n",
    "#             pep = mass = numPeaks = 0\n",
    "#             spec = []\n",
    "#             new = int((i/len(lines)) * 100)\n",
    "#             if (new > prev):\n",
    "#                 #clear_output(wait=True)\n",
    "#                 print(str(new) + '%')\n",
    "#                 prev = new\n",
    "    \n",
    "#     print('max peaks: ' + str(maxpeaks))\n",
    "#     print('count: ' + str(count))\n",
    "#     print('max moz: ' + str(maxmoz))\n",
    "#     return dataset, label\n",
    "# # print('max peaks: ' + str(maxpeaks))\n",
    "# # print('count: ' + str(count))\n",
    "# # print('max moz: ' + str(maxmoz))\n",
    "# # #fo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99%\n",
      "<class 'list'>\n",
      "len of file: 50017570\n",
      "130172\n"
     ]
    }
   ],
   "source": [
    "f = open(\"data/human_consensus_final_true_lib.msp\", \"r\")\n",
    "lines = f.readlines()\n",
    "newcontents = []\n",
    "specid = 0\n",
    "prev = 0\n",
    "num_specs = 0\n",
    "using_mods = config.get_config(section='input', key='use_mods')\n",
    "for i, line in enumerate(lines):\n",
    "    if line.startswith('Name') and '_' in line:\n",
    "        l_charge = int(line[line.find('_') - 1])\n",
    "        if l_charge != config.get_config(section='input', key='charge'):\n",
    "            continue\n",
    "        if using_mods:\n",
    "            num_specs += 1\n",
    "        elif '(' not in line and ')' not in line:\n",
    "            num_specs += 1\n",
    "        new = int((i/len(lines)) * 100)\n",
    "        if (new > prev):\n",
    "            clear_output(wait=True)\n",
    "            print(str(new) + '%')\n",
    "            prev = new\n",
    "f.close()\n",
    "print(type(lines))\n",
    "print('len of file: ' + str(len(lines)))\n",
    "print(num_specs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99%\n",
      "max peaks: 251\n",
      "count: 130172\n",
      "max moz: 2616.7\n"
     ]
    }
   ],
   "source": [
    "dataset, label = reader.read_msp_with_decoy(\"data/human_consensus_final_true_lib.msp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "splitting...\n"
     ]
    }
   ],
   "source": [
    "print('splitting...')\n",
    "tmpTrainData, tmpTestData = train_test_split(\n",
    "            dataset, test_size = 0.2, random_state = rand.randint(0, 1000), shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_peps = set([item[0] for item in tmpTrainData])\n",
    "test_peps = set([item[0] for item in tmpTestData])\n",
    "print(sorted(list(train_peps))[0:10])\n",
    "print(sorted(list(test_peps))[0:10])\n",
    "print(len(train_peps))\n",
    "print(len(test_peps))\n",
    "common = train_peps.intersection(test_peps)\n",
    "print(len(common))\n",
    "print(len(tmpTestData))\n",
    "for item in tmpTestData:\n",
    "    if item[0] in common:\n",
    "        tmpTestData.remove(item)\n",
    "        \n",
    "print(len(tmpTestData))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('converting to tensors...')\n",
    "XTrainTensor = torch.tensor(tmpTrainData, dtype=torch.float)\n",
    "XTestTensor = torch.tensor(tmpTestData, dtype=torch.float)\n",
    "print('done')\n",
    "del dataset, tmpTrainData, tmpTestData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del tmpTrainData, tmpTestData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=XTrainTensor, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=XTestTensor, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "do_learn = True\n",
    "save_frequency = 2\n",
    "lr = 0.001\n",
    "num_epochs = 200\n",
    "weight_decay = 0.0001\n",
    "margin = 0.2\n",
    "#torch.manual_seed(0)\n",
    "#torch.cuda.manual_seed(0)\n",
    "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_loader = torch.load('train_loader.pt')\n",
    "#test_loader = torch.load('test_loader.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.spec_size = config.get_config(section='input', key='spec_size')\n",
    "        self.searching = False\n",
    "        \n",
    "        self.linear1_1 = nn.Linear(self.spec_size, 1024)\n",
    "        self.linear1_2 = nn.Linear(1024, 512)\n",
    "        #self.linear1_3 = nn.Linear(512, 256)\n",
    "        \n",
    "        self.linear2_1 = nn.Linear(self.spec_size, 1024)\n",
    "        self.linear2_2 = nn.Linear(1024, 512)\n",
    "        #self.linear2_3 = nn.Linear(512, 256)\n",
    "        \n",
    "        self.dropout1 = nn.Dropout(0.5)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        #self.dropout3 = nn.Dropout(0.3)\n",
    "        \n",
    "    def forward(self, data):\n",
    "        res = []\n",
    "#         x = data[:, 0]\n",
    "#         x = self.linear1_1(x.view(-1, self.spec_size))\n",
    "#         x = F.relu(x)\n",
    "#         x = self.dropout2(x)\n",
    "        #x = self.linear1_2(x)\n",
    "        #x = F.relu(x)\n",
    "        #x = self.dropout2(x)\n",
    "        #x = self.dropout2(x)\n",
    "        #x = self.linear1_3(x)\n",
    "        #x = F.relu(x)\n",
    "        #if not self.searching:\n",
    "        #    x = F.normalize(x)\n",
    "        #res.append(x)\n",
    "        for i in range(data.shape[1]):\n",
    "            x = data[:, i]\n",
    "            x = self.linear2_1(x.view(-1, self.spec_size))\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout1(x)\n",
    "            x = self.linear2_2(x)\n",
    "            x = F.relu(x)\n",
    "            #x = self.dropout2(x)\n",
    "            #x = self.dropout2(x)\n",
    "            #x = self.linear2_3(x)\n",
    "            #x = F.relu(x)\n",
    "            #if not self.searching:\n",
    "            #x = F.normalize(x)\n",
    "            #x = self.linear1_3(x)\n",
    "            #x = F.relu(x)\n",
    "            res.append(x)\n",
    "        \n",
    "        return res\n",
    "    \n",
    "    def name(self):\n",
    "        return \"Net\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for (tid, data) in enumerate(train_loader):\n",
    "#     if tid == 0:\n",
    "#         print(data[:,0:3:2].shape)\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hinge = torch.nn.HingeEmbeddingLoss()\n",
    "triplet_loss = nn.TripletMarginLoss(margin=margin, p=2, reduction='mean')\n",
    "\n",
    "def train(model, device, train_loader, epoch, optimizer):\n",
    "    model.train()\n",
    "    \n",
    "    accurate_labels = 0\n",
    "    all_labels = 0\n",
    "    for (batch_idx, data) in enumerate(train_loader):\n",
    "        \n",
    "        data = data.to(device)    \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        Q, P, N = model(data)\n",
    "        \n",
    "        # TODO: Mine hard triplest before calculating the loss.\n",
    "        \n",
    "        loss = triplet_loss(Q, P, N)\n",
    "        \n",
    "        loss.backward()\n",
    "            \n",
    "        optimizer.step()\n",
    "        \n",
    "        accurate_labels = accurate_labels + 2*torch.sum(F.pairwise_distance(Q, P)**2 - \n",
    "                                                        F.pairwise_distance(Q, N)**2 + margin < 0)\n",
    "        \n",
    "        all_labels = all_labels + 2*len(Q)  \n",
    "    \n",
    "    accuracy = 100. * float(accurate_labels) / all_labels\n",
    "    train_accuracy.append(accuracy)\n",
    "    train_loss.append(loss/batch_size)\n",
    "    print('Epoch: ' + str(epoch))\n",
    "    print('Train accuracy: {}/{} ({:.3f}%)\\tLoss: {:.6f}'.format(accurate_labels, all_labels, accuracy, loss))\n",
    "    \n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        accurate_labels = 0\n",
    "        all_labels = 0\n",
    "        loss = 0\n",
    "        \n",
    "        for (batch_idx, data) in enumerate(test_loader):\n",
    "            \n",
    "            data = data.to(device)    \n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            Q, P, N = model(data)\n",
    "            \n",
    "            loss = triplet_loss(Q, P, N)\n",
    "            \n",
    "            accurate_labels = accurate_labels + 2*torch.sum(F.pairwise_distance(Q, P)**2 - \n",
    "                                                        F.pairwise_distance(Q, N)**2 + margin < 0)\n",
    "            \n",
    "            all_labels = all_labels + 2*len(Q)\n",
    "                \n",
    "        accuracy = 100. * float(accurate_labels) / all_labels\n",
    "        test_accuracy.append(accuracy)\n",
    "        test_loss.append(loss/batch_size)\n",
    "        print('Test accuracy: {}/{} ({:.3f}%)\\tLoss: {:.6f}'.format(accurate_labels, all_labels, accuracy, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def oneshot(model, device, data):\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(len(data)):\n",
    "            data[i] = data[i].to(device)\n",
    "            \n",
    "        output = model(data)\n",
    "        return torch.squeeze(torch.argmax(output, dim=1)).cpu().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "test_loss = []\n",
    "train_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "model = Net().to(device)\n",
    "# model.linear1_1.weight.requires_grad = False\n",
    "# model.linear1_1.bias.requires_grad = False\n",
    "# model.linear1_2.weight.requires_grad = False\n",
    "# model.linear1_2.bias.requires_grad = False\n",
    "   \n",
    "if do_learn: # training mode\n",
    "    \n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    #optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        train(model, device, train_loader, epoch, optimizer)\n",
    "        test(model, device, test_loader)\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model, 'models/siamese99.7%.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove modifications  \n",
    "use one charge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
